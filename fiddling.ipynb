{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9aac1c3-bb06-45aa-aefe-f21d75456481",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7b3cb7f-5ddd-4fe1-9f41-4024af5f86b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset conv_ai_3 (/home/lazerdance/.cache/huggingface/datasets/conv_ai_3/conv_ai_3/1.0.0/fee8db8bfc2268ecf5e609156cb7bdafa364dfca7d706ff808a2e71e8a006f64)\n"
     ]
    }
   ],
   "source": [
    "ds = load_dataset(\"conv_ai_3\", split=\"train+validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "067fabe6-2b36-4638-b846-a226904334e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['topic_id', 'initial_request', 'topic_desc', 'clarification_need', 'facet_id', 'facet_desc', 'question_id', 'question', 'answer'],\n",
       "    num_rows: 11489\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5d57b00-ed6b-4167-a5dc-53827e9a704c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'topic_id': 1,\n",
       " 'initial_request': 'Tell me about Obama family tree.',\n",
       " 'topic_desc': \"Find information on President Barack Obama\\\\'s family history, including genealogy, national origins, places and dates of birth, etc.\",\n",
       " 'clarification_need': 2,\n",
       " 'facet_id': 'F0001',\n",
       " 'facet_desc': 'Find the TIME magazine photo essay \"Barack Obama\\'s Family Tree\".',\n",
       " 'question_id': 'Q00384',\n",
       " 'question': 'are you interested in seeing barack obamas family',\n",
       " 'answer': 'yes am interested in obamas family'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dafbd591-2d4b-4635-aa29-788d67fb06a7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text:hello how are you today?\tlabels:i'm great thanks! what are you doing?\ttext:i've just been biking.\tlabels:oh nice, i haven't got on a bike in years!   episode_done:True\n"
     ]
    }
   ],
   "source": [
    "print(\"text:hello how are you today?\\tlabels:i'm great thanks! what are you doing?\\ttext:i've just been biking.\\tlabels:oh nice, i haven't got on a bike in years!   episode_done:True\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "daa9995a-fd6e-48eb-89c9-5ecda2c4b24e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fab14ea6-a639-4cef-9792-74fc6fb9cc27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_dataset(filename, ds_list):\n",
    "    with open(filename,\"w\") as file:\n",
    "        file.writelines(ds_list)\n",
    "        file.close()\n",
    "        \n",
    "def get_list_from_hfdataset(dataset):\n",
    "    return [f\"text:{ex['initial_request']}\\tlabels:{ex['question']}\\ntext:{ex['answer']}\\tlabels:{ex['facet_desc']}\\tepisode_done:True\\n\" for ex in tqdm(dataset.shuffle())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15e07fbe-3615-41a9-ac7d-6f114dbd6902",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset conv_ai_3 (/home/lazerdance/.cache/huggingface/datasets/conv_ai_3/conv_ai_3/1.0.0/fee8db8bfc2268ecf5e609156cb7bdafa364dfca7d706ff808a2e71e8a006f64)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "953d0f07ecc14d299f95aad1509a71c1"
      },
      "application/json": {
       "n": 0,
       "total": 2,
       "elapsed": 0.0050504207611083984,
       "ncols": null,
       "nrows": null,
       "prefix": "",
       "ascii": false,
       "unit": "it",
       "unit_scale": false,
       "rate": null,
       "bar_format": null,
       "postfix": null,
       "unit_divisor": 1000,
       "initial": 0,
       "colour": null
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/9176 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "00cc7a3de49846958774da5e776ee19d"
      },
      "application/json": {
       "n": 0,
       "total": 9176,
       "elapsed": 0.004736900329589844,
       "ncols": null,
       "nrows": null,
       "prefix": "",
       "ascii": false,
       "unit": "it",
       "unit_scale": false,
       "rate": null,
       "bar_format": null,
       "postfix": null,
       "unit_divisor": 1000,
       "initial": 0,
       "colour": null
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/2313 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "79ab75f9931f49b7b0b183583d4f6852"
      },
      "application/json": {
       "n": 0,
       "total": 2313,
       "elapsed": 0.0050127506256103516,
       "ncols": null,
       "nrows": null,
       "prefix": "",
       "ascii": false,
       "unit": "it",
       "unit_scale": false,
       "rate": null,
       "bar_format": null,
       "postfix": null,
       "unit_divisor": 1000,
       "initial": 0,
       "colour": null
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"conv_ai_3\")\n",
    "train_dataset, validation_dataset = dataset[\"train\"], dataset[\"validation\"]\n",
    "train_dataset_list, validation_dataset_list = get_list_from_hfdataset(train_dataset), get_list_from_hfdataset(validation_dataset)\n",
    "save_dataset(\"parlai/tasks/convai3/huggingface/convai3_train.txt\", train_dataset_list)\n",
    "save_dataset(\"parlai/tasks/convai3/huggingface/convai3_valid.txt\", validation_dataset_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68589390-c905-4c97-9e5d-f284ebb03787",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: py: Permission denied\r\n"
     ]
    }
   ],
   "source": [
    "!parlai display_data --task fromfile:parlaiformat --fromfile-datapath ./convai3data --fromfile-datatype-extension true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dd898797-660b-4d1e-a03c-9cff0f2c1b48",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:16:56 | building dictionary first...\n",
      "19:16:56 | \u001B[33mOverriding opt[\"batchsize\"] to 256 (previously: 16)\u001B[0m\n",
      "19:16:56 | \u001B[33mOverriding opt[\"fromfile_datapath\"] to ./convai3data (previously: ../Amrou/dataset_convai3.txt)\u001B[0m\n",
      "19:16:56 | \u001B[33mOverriding opt[\"fromfile_datatype_extension\"] to True (previously: False)\u001B[0m\n",
      "19:16:56 | \u001B[33mOverriding opt[\"num_epochs\"] to 500.0 (previously: 5000.0)\u001B[0m\n",
      "19:16:56 | \u001B[33mOverriding opt[\"gpu\"] to 0 (previously: -1)\u001B[0m\n",
      "19:16:56 | \u001B[33mOverriding opt[\"save_every_n_secs\"] to 600.0 (previously: 60.0)\u001B[0m\n",
      "19:16:56 | \u001B[33myour model is being loaded with opts that do not exist in the model you are initializing the weights with: download_path: None,verbose: False,datapath: /home/yacine_zahidi_orange_com/envs/general-env39/lib/python3.9/site-packages/data,load_from_checkpoint: True,interactive_mode: False\u001B[0m\n",
      "19:16:56 | \u001B[33myour model is being loaded with opts that differ from the model you are initializing the weights with. Add the following args to your run command to change this: \n",
      "--save-every-n-secs 1800.0 --fromfile-datapath ./dataset_convai3.txt --fromfile-datatype-extension False\u001B[0m\n",
      "19:16:56 | Using CUDA\n",
      "19:16:56 | loading dictionary from /home/yacine_zahidi_orange_com/envs/general-env39/lib/python3.9/site-packages/data/models/blender/blender_90M/model.checkpoint.dict\n",
      "19:16:56 | num words = 54944\n",
      "19:16:57 | \u001B[33mDEPRECATED: XLM should only be used for backwards compatibility, as it involves a less-stable layernorm operation.\u001B[0m\n",
      "19:16:59 | Total parameters: 87,508,992 (87,508,992 trainable)\n",
      "19:16:59 | Loading existing model params from /home/yacine_zahidi_orange_com/envs/general-env39/lib/python3.9/site-packages/data/models/blender/blender_90M/model.checkpoint\n",
      "19:17:00 | Opt:\n",
      "19:17:00 |     activation: gelu\n",
      "19:17:00 |     adafactor_eps: '[1e-30, 0.001]'\n",
      "19:17:00 |     adam_eps: 1e-08\n",
      "19:17:00 |     add_p1_after_newln: False\n",
      "19:17:00 |     aggregate_micro: False\n",
      "19:17:00 |     allow_missing_init_opts: False\n",
      "19:17:00 |     attention_dropout: 0.0\n",
      "19:17:00 |     batchsize: 256\n",
      "19:17:00 |     beam_block_full_context: False\n",
      "19:17:00 |     beam_block_list_filename: None\n",
      "19:17:00 |     beam_block_ngram: 3\n",
      "19:17:00 |     beam_context_block_ngram: 3\n",
      "19:17:00 |     beam_delay: 30\n",
      "19:17:00 |     beam_length_penalty: 0.65\n",
      "19:17:00 |     beam_min_length: 20\n",
      "19:17:00 |     beam_size: 10\n",
      "19:17:00 |     betas: '[0.9, 0.999]'\n",
      "19:17:00 |     bpe_add_prefix_space: None\n",
      "19:17:00 |     bpe_debug: False\n",
      "19:17:00 |     bpe_dropout: None\n",
      "19:17:00 |     bpe_merge: None\n",
      "19:17:00 |     bpe_vocab: None\n",
      "19:17:00 |     checkpoint_activations: False\n",
      "19:17:00 |     compute_tokenized_bleu: False\n",
      "19:17:00 |     datapath: /home/yacine_zahidi_orange_com/envs/general-env39/lib/python3.9/site-packages/data\n",
      "19:17:00 |     datatype: train\n",
      "19:17:00 |     delimiter: '\\n'\n",
      "19:17:00 |     dict_class: parlai.core.dict:DictionaryAgent\n",
      "19:17:00 |     dict_endtoken: __end__\n",
      "19:17:00 |     dict_file: /home/yacine_zahidi_orange_com/envs/general-env39/lib/python3.9/site-packages/data/models/blender/blender_90M/model.checkpoint.dict\n",
      "19:17:00 |     dict_include_test: False\n",
      "19:17:00 |     dict_include_valid: False\n",
      "19:17:00 |     dict_initpath: None\n",
      "19:17:00 |     dict_language: english\n",
      "19:17:00 |     dict_loaded: True\n",
      "19:17:00 |     dict_lower: True\n",
      "19:17:00 |     dict_max_ngram_size: -1\n",
      "19:17:00 |     dict_maxexs: -1\n",
      "19:17:00 |     dict_maxtokens: -1\n",
      "19:17:00 |     dict_minfreq: 0\n",
      "19:17:00 |     dict_nulltoken: __null__\n",
      "19:17:00 |     dict_starttoken: __start__\n",
      "19:17:00 |     dict_textfields: text,labels\n",
      "19:17:00 |     dict_tokenizer: bpe\n",
      "19:17:00 |     dict_unktoken: __unk__\n",
      "19:17:00 |     display_examples: False\n",
      "19:17:00 |     download_path: None\n",
      "19:17:00 |     dropout: 0.1\n",
      "19:17:00 |     dynamic_batching: None\n",
      "19:17:00 |     embedding_projection: random\n",
      "19:17:00 |     embedding_size: 512\n",
      "19:17:00 |     embedding_type: random\n",
      "19:17:00 |     embeddings_scale: True\n",
      "19:17:00 |     eval_batchsize: None\n",
      "19:17:00 |     eval_dynamic_batching: None\n",
      "19:17:00 |     evaltask: None\n",
      "19:17:00 |     ffn_size: 2048\n",
      "19:17:00 |     final_extra_opt: \n",
      "19:17:00 |     force_fp16_tokens: True\n",
      "19:17:00 |     fp16: True\n",
      "19:17:00 |     fp16_impl: safe\n",
      "19:17:00 |     fromfile_datapath: ./convai3data\n",
      "19:17:00 |     fromfile_datatype_extension: True\n",
      "19:17:00 |     gpu: 0\n",
      "19:17:00 |     gpu_beam_blocking: False\n",
      "19:17:00 |     gradient_clip: 0.1\n",
      "19:17:00 |     hide_labels: False\n",
      "19:17:00 |     history_add_global_end_token: None\n",
      "19:17:00 |     history_reversed: False\n",
      "19:17:00 |     history_size: -1\n",
      "19:17:00 |     image_cropsize: 224\n",
      "19:17:00 |     image_mode: raw\n",
      "19:17:00 |     image_size: 256\n",
      "19:17:00 |     include_checked_sentence: True\n",
      "19:17:00 |     include_knowledge: True\n",
      "19:17:00 |     include_knowledge_separator: False\n",
      "19:17:00 |     inference: beam\n",
      "19:17:00 |     init_model: /home/yacine_zahidi_orange_com/envs/general-env39/lib/python3.9/site-packages/data/models/blender/blender_90M/model.checkpoint\n",
      "19:17:00 |     init_opt: None\n",
      "19:17:00 |     interactive_mode: False\n",
      "19:17:00 |     invsqrt_lr_decay_gamma: -1\n",
      "19:17:00 |     is_debug: False\n",
      "19:17:00 |     label_truncate: 128\n",
      "19:17:00 |     label_type: response\n",
      "19:17:00 |     learn_positional_embeddings: True\n",
      "19:17:00 |     learningrate: 7.5e-06\n",
      "19:17:00 |     load_from_checkpoint: True\n",
      "19:17:00 |     log_every_n_secs: 2\n",
      "19:17:00 |     log_every_n_steps: 50\n",
      "19:17:00 |     log_keep_fields: all\n",
      "19:17:00 |     loglevel: info\n",
      "19:17:00 |     lr_scheduler: reduceonplateau\n",
      "19:17:00 |     lr_scheduler_decay: 0.5\n",
      "19:17:00 |     lr_scheduler_patience: 3\n",
      "19:17:00 |     max_lr_steps: -1\n",
      "19:17:00 |     max_train_steps: 50000\n",
      "19:17:00 |     max_train_time: -1\n",
      "19:17:00 |     metrics: default\n",
      "19:17:00 |     model: transformer/generator\n",
      "19:17:00 |     model_file: /home/yacine_zahidi_orange_com/envs/general-env39/lib/python3.9/site-packages/data/models/blender/blender_90M/model\n",
      "19:17:00 |     model_parallel: False\n",
      "19:17:00 |     momentum: 0\n",
      "19:17:00 |     multitask_weights: '[1.0, 3.0, 3.0, 3.0]'\n",
      "19:17:00 |     mutators: None\n",
      "19:17:00 |     n_decoder_layers: -1\n",
      "19:17:00 |     n_encoder_layers: -1\n",
      "19:17:00 |     n_heads: 16\n",
      "19:17:00 |     n_layers: 8\n",
      "19:17:00 |     n_positions: 512\n",
      "19:17:00 |     n_segments: 0\n",
      "19:17:00 |     nesterov: True\n",
      "19:17:00 |     no_cuda: False\n",
      "19:17:00 |     num_epochs: 500.0\n",
      "19:17:00 |     num_topics: 5\n",
      "19:17:00 |     num_workers: 0\n",
      "19:17:00 |     numthreads: 1\n",
      "19:17:00 |     nus: [0.7]\n",
      "19:17:00 |     optimizer: adamax\n",
      "19:17:00 |     output_scaling: 1.0\n",
      "19:17:00 |     override: \"{'model_file': '/home/yacine_zahidi_orange_com/envs/general-env39/lib/python3.9/site-packages/data/models/blender/blender_90M/model', 'batchsize': 256, 'wandb_log': True, 'task': 'fromfile:parlaiformat', 'fromfile_datapath': './convai3data', 'fromfile_datatype_extension': True, 'num_epochs': 500.0, 'gpu': 0, 'save_every_n_secs': 600.0}\"\n",
      "19:17:00 |     parlai_home: /private/home/edinan/ParlAI\n",
      "19:17:00 |     person_tokens: False\n",
      "19:17:00 |     rank_candidates: False\n",
      "19:17:00 |     relu_dropout: 0.0\n",
      "19:17:00 |     save_after_valid: True\n",
      "19:17:00 |     save_every_n_secs: 600.0\n",
      "19:17:00 |     save_format: conversations\n",
      "19:17:00 |     seed: None\n",
      "19:17:00 |     share_word_embeddings: True\n",
      "19:17:00 |     short_final_eval: False\n",
      "19:17:00 |     show_advanced_args: False\n",
      "19:17:00 |     skip_generation: False\n",
      "19:17:00 |     special_tok_lst: None\n",
      "19:17:00 |     split_lines: False\n",
      "19:17:00 |     starttime: Feb10_07-25\n",
      "19:17:00 |     task: fromfile:parlaiformat\n",
      "19:17:00 |     teacher_seed: None\n",
      "19:17:00 |     temperature: 1.0\n",
      "19:17:00 |     tensorboard_log: False\n",
      "19:17:00 |     tensorboard_logdir: None\n",
      "19:17:00 |     text_truncate: 512\n",
      "19:17:00 |     topk: 10\n",
      "19:17:00 |     topp: 0.9\n",
      "19:17:00 |     train_experiencer_only: False\n",
      "19:17:00 |     truncate: -1\n",
      "19:17:00 |     update_freq: 1\n",
      "19:17:00 |     use_reply: label\n",
      "19:17:00 |     validation_cutoff: 1.0\n",
      "19:17:00 |     validation_every_n_epochs: 0.25\n",
      "19:17:00 |     validation_every_n_secs: -1\n",
      "19:17:00 |     validation_every_n_steps: -1\n",
      "19:17:00 |     validation_max_exs: 20000\n",
      "19:17:00 |     validation_metric: ppl\n",
      "19:17:00 |     validation_metric_mode: min\n",
      "19:17:00 |     validation_patience: 15\n",
      "19:17:00 |     validation_share_agent: False\n",
      "19:17:00 |     variant: xlm\n",
      "19:17:00 |     verbose: False\n",
      "19:17:00 |     wandb_entity: None\n",
      "19:17:00 |     wandb_log: True\n",
      "19:17:00 |     wandb_log_model: False\n",
      "19:17:00 |     wandb_name: None\n",
      "19:17:00 |     wandb_project: None\n",
      "19:17:00 |     warmup_rate: 0.0001\n",
      "19:17:00 |     warmup_updates: -1\n",
      "19:17:00 |     weight_decay: None\n",
      "19:17:00 |     world_logs: \n",
      "19:17:00 | creating task(s): fromfile:parlaiformat\n",
      "19:17:00 | Loading ParlAI text data: ./convai3data_train.txt\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mell-hol\u001B[0m. Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Tracking run with wandb version 0.13.10\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Run data is saved locally in \u001B[35m\u001B[1m/home/yacine_zahidi_orange_com/envs/general-env39/lib/python3.9/site-packages/data/models/blender/blender_90M/wandb/run-20230222_191703-071orfew\u001B[0m\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Run \u001B[1m`wandb offline`\u001B[0m to turn off syncing.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Syncing run \u001B[33mwandering-surf-1\u001B[0m\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: ⭐️ View project at \u001B[34m\u001B[4mhttps://wandb.ai/ell-hol/2023-02-22-19-17\u001B[0m\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: 🚀 View run at \u001B[34m\u001B[4mhttps://wandb.ai/ell-hol/2023-02-22-19-17/runs/071orfew\u001B[0m\n",
      "19:17:04 | training...\n",
      "19:17:15 | time:69387s total_exs:4288982 total_steps:348701 epochs:233.71 time_left:79062s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.14     1  4388 20384       0          0  1189 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    15.05    .3290 11.56  2.53 7.5e-06  2959 13743       0          0 12.56   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .6723     .3084               348701 7347 34127 4.648\n",
      "\n",
      "19:17:25 | time:69397s total_exs:4301782 total_steps:348751 epochs:234.40 time_left:78632s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.11     1  4380 21823       0          0  1275 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    9.524    .3148 11.51 1.748 7.5e-06  2946 14678       0          0 5.742   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .7222     .3200               348751 7326 36501 4.985\n",
      "\n",
      "19:17:35 | time:69407s total_exs:4314582 total_steps:348801 epochs:235.10 time_left:78204s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.12     1  4382 22867       0          0  1336 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    7.214    .3148 11.58 1.508 7.5e-06  2965 15474       0          0 4.517   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .7395     .3306               348801 7347 38340 5.222\n",
      "\n",
      "19:17:45 | time:69417s total_exs:4327382 total_steps:348851 epochs:235.80 time_left:77779s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   16.99     1  4350 21626       0          0  1273 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    6.071    .3017 11.52 1.345 7.5e-06  2949 14657       0          0 3.839   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .7546     .3380               348851 7299 36283 4.974\n",
      "\n",
      "19:17:54 | time:69427s total_exs:4340182 total_steps:348901 epochs:236.50 time_left:77355s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.09     1  4374 23215       0          0  1359 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    4.992    .3017 11.54 1.264 7.5e-06  2955 15683       0          0 3.539   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .7595     .3445               348901 7329 38898 5.311\n",
      "\n",
      "19:18:06 | time:69438s total_exs:4352982 total_steps:348951 epochs:237.19 time_left:76936s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.08     1  4373 19620       0          0  1149 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    4.411    .3291 11.52 1.175 7.5e-06  2950 13236       0          0 3.237   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .7690     .3489               348951 7323 32856 4.489\n",
      "\n",
      "19:18:15 | time:69447s total_exs:4365782 total_steps:349001 epochs:237.89 time_left:76517s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.03     1  4361 23065       0          0  1354 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    3.914    .3148 11.51 1.139 7.5e-06  2946 15582       0          0 3.125   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .7725     .3489               349001 7307 38647 5.292\n",
      "\n",
      "19:18:25 | time:69457s total_exs:4378582 total_steps:349051 epochs:238.59 time_left:76101s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.14     1  4387 21876       0          0  1276 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "     3.79    .3148 11.55 1.091 7.5e-06  2958 14749       0          0 2.979   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .7787     .3527               349051 7345 36626 4.989\n",
      "\n",
      "19:18:35 | time:69467s total_exs:4391382 total_steps:349101 epochs:239.29 time_left:75688s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.12     1  4382 22800       0          0  1332 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    3.188    .3017 11.52 1.063 7.5e-06  2949 15343       0          0 2.896   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .7822     .3585               349101 7331 38144 5.206\n",
      "\n",
      "19:18:45 | time:69477s total_exs:4404182 total_steps:349151 epochs:239.98 time_left:75277s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.12     1  4382 21773       0          0  1272 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    2.845    .3148 11.55 1.023 7.5e-06  2956 14686       0          0 2.781   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .7872     .3647               349151 7338 36459 4.972\n",
      "\n",
      "19:18:54 | time:69487s total_exs:4416982 total_steps:349201 epochs:240.68 time_left:74867s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.08     1  4372 23221       0          0  1360 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "      2.7    .3148 11.54 .9864 7.5e-06  2955 15698       0          0 2.681   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .7914     .3663               349201 7327 38920 5.315\n",
      "\n",
      "19:19:05 | time:69498s total_exs:4429782 total_steps:349251 epochs:241.38 time_left:74462s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "      17     1  4353 19864       0          0  1168 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    2.626    .3148 11.49 .9706 7.5e-06  2943 13428       0          0 2.639   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .7944     .3677               349251 7296 33292 4.566\n",
      "\n",
      "19:19:15 | time:69507s total_exs:4442582 total_steps:349301 epochs:242.08 time_left:74058s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   16.94     1  4337 22797       0          0  1346 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    2.519    .3148 11.49 .9366 7.5e-06  2941 15459       0          0 2.551   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .7984     .3671               349301 7278 38257 5.259\n",
      "\n",
      "19:19:25 | time:69517s total_exs:4455382 total_steps:349351 epochs:242.77 time_left:73656s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.11     1  4379 21870       0          0  1279 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    2.723    .3017 11.53 .9270 7.5e-06  2953 14746       0          0 2.527   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .8001     .3702               349351 7332 36617 4.997\n",
      "\n",
      "19:19:35 | time:69527s total_exs:4468182 total_steps:349401 epochs:243.47 time_left:73256s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.06     1  4368 22769       0          0  1335 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    2.392    .3148 11.45 .9075 7.5e-06  2932 15283       0          0 2.478   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .8021     .3765               349401 7299 38052 5.216\n",
      "\n",
      "19:19:45 | time:69537s total_exs:4480982 total_steps:349451 epochs:244.17 time_left:72858s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.07     1  4369 21806       0          0  1278 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
      "    2.346    .3290 11.52 .8921 7.5e-06  2949 14715       0          0 2.44   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .8042     .3802               349451 7318 36521 4.993\n",
      "\n",
      "19:19:54 | time:69547s total_exs:4493782 total_steps:349501 epochs:244.87 time_left:72463s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.09     1  4375 23055       0          0  1349 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    2.298    .3291 11.54 .8739 7.5e-06  2953 15564       0          0 2.396   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .8076     .3721               349501 7328 38619 5.273\n",
      "\n",
      "19:20:05 | time:69558s total_exs:4506582 total_steps:349551 epochs:245.56 time_left:72071s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "    17.1     1  4378 19889       0          0  1163 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    2.444    .3290 11.56 .8596 7.5e-06  2960 13444       0          0 2.362   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .8099     .3781               349551 7338 33333 4.545\n",
      "\n",
      "19:20:15 | time:69567s total_exs:4519382 total_steps:349601 epochs:246.26 time_left:71680s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "    17.1     1  4377 22892       0          0  1339 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    2.539    .3290 11.56 .8436 7.5e-06  2961 15485       0          0 2.325   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .8118     .3811               349601 7338 38377 5.233\n",
      "\n",
      "19:20:25 | time:69577s total_exs:4532182 total_steps:349651 epochs:246.96 time_left:71291s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.12     1  4384 21596       0          0  1261 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    2.235    .3148 11.55 .8264 7.5e-06  2958 14571       0          0 2.285   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .8146     .3864               349651 7341 36168 4.986\n",
      "\n",
      "19:20:35 | time:69587s total_exs:4544982 total_steps:349701 epochs:247.66 time_left:70904s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "      17     1  4353 23004       0          0  1353 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    2.414    .3017  11.5 .8142 7.5e-06  2944 15556       0          0 2.257   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .8160     .3819               349701 7297 38561 5.288\n",
      "\n",
      "19:20:45 | time:69597s total_exs:4557782 total_steps:349751 epochs:248.35 time_left:70520s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.14     1  4388 21923       0          0  1279 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    2.321    .3017 11.59 .8040 7.5e-06  2966 14819       0          0 2.234   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .8179     .3882               349751 7353 36741 4.999\n",
      "\n",
      "19:20:54 | time:69606s total_exs:4570582 total_steps:349801 epochs:249.05 time_left:70137s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.06     1  4367 23037       0          0  1350 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    2.362    .3290 11.53 .8039 7.5e-06  2951 15567       0          0 2.234   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .8165     .3835               349801 7318 38604 5.278\n",
      "\n",
      "19:21:05 | time:69617s total_exs:4583382 total_steps:349851 epochs:249.75 time_left:69758s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.19     1  4402 20155       0          0  1172 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    2.218    .3148 11.58 .7937 7.5e-06  2964 13573       0          0 2.211   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .8178     .3887               349851 7366 33728 4.581\n",
      "\n",
      "19:21:15 | time:69627s total_exs:4596182 total_steps:349901 epochs:250.45 time_left:69379s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.17     1  4395 23134       0          0  1348 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    2.217    .3148 11.53 .7811 7.5e-06  2953 15542       0          0 2.184   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .8214     .3911               349901 7347 38677 5.267\n",
      "\n",
      "19:21:25 | time:69637s total_exs:4608982 total_steps:349951 epochs:251.14 time_left:69003s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.13     1  4386 21398       0          0  1249 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    2.127    .3148  11.6 .7714 7.5e-06  2968 14483       0          0 2.163   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .8232     .3899               349951 7354 35882 4.882\n",
      "\n",
      "19:21:35 | time:69647s total_exs:4621782 total_steps:350001 epochs:251.84 time_left:68629s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.02     1  4358 22887       0          0  1344 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    2.239    .3017 11.54 .7543 7.5e-06  2955 15520       0          0 2.126   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .8256     .3865               350001 7313 38406 5.255\n",
      "\n",
      "19:21:45 | time:69657s total_exs:4634582 total_steps:350051 epochs:252.54 time_left:68257s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.13     1  4386 21909       0          0  1279 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "     2.27    .3290 11.51 .7395 7.5e-06  2948 14725       0          0 2.095   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .8273     .3948               350051 7334 36634 4.998\n",
      "\n",
      "19:21:54 | time:69666s total_exs:4647382 total_steps:350101 epochs:253.24 time_left:67886s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.09     1  4376 23004       0          0  1346 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
      "    2.137    .3148 11.55 .7372 7.5e-06  2957 15543       0          0 2.09   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps  ups  \n",
      "        .8273     .3953               350101 7333 38547 5.26\n",
      "\n",
      "19:22:05 | time:69678s total_exs:4660182 total_steps:350151 epochs:253.93 time_left:67519s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.03     1  4360 19764       0          0  1160 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "     2.19    .3148 11.58 .7255 7.5e-06  2964 13434       0          0 2.066   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .8301     .3934               350151 7323 33198 4.536\n",
      "\n",
      "19:22:15 | time:69687s total_exs:4672982 total_steps:350201 epochs:254.63 time_left:67152s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.06     1  4366 23067       0          0  1352 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    2.225    .3148 11.51 .7197 7.5e-06  2945 15560       0          0 2.054   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .8306     .3952               350201 7312 38627 5.287\n",
      "\n",
      "19:22:25 | time:69697s total_exs:4685782 total_steps:350251 epochs:255.33 time_left:66788s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "      17     1  4351 21376       0          0  1258 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    2.119    .3148 11.53 .7016 7.5e-06  2952 14504       0          0 2.017   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .8336     .3933               350251 7303 35880 4.916\n",
      "\n",
      "19:22:35 | time:69707s total_exs:4698582 total_steps:350301 epochs:256.03 time_left:66426s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.15     1  4390 22661       0          0  1322 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    2.249    .3290 11.51 .7046 7.5e-06  2948 15218       0          0 2.023   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .8328     .3951               350301 7337 37880 5.165\n",
      "\n",
      "19:22:45 | time:69717s total_exs:4711382 total_steps:350351 epochs:256.72 time_left:66066s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.12     1  4383 21793       0          0  1273 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    2.124    .3148 11.54 .6999 7.5e-06  2955 14694       0          0 2.014   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .8348     .3961               350351 7338 36487 4.975\n",
      "\n",
      "19:22:54 | time:69727s total_exs:4724182 total_steps:350401 epochs:257.42 time_left:65707s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.05     1  4366 23067       0          0  1353 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    2.175    .3148 11.53 .6733 7.5e-06  2952 15597       0          0 1.961   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .8377     .3955               350401 7318 38664 5.286\n",
      "\n",
      "19:23:05 | time:69738s total_exs:4736982 total_steps:350451 epochs:258.12 time_left:65351s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   16.97     1  4344 19987       0          0  1178 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
      "    2.187    .3148  11.5 .6779 7.5e-06  2945 13547       0          0 1.97   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .8365     .3951               350451 7289 33534 4.603\n",
      "\n",
      "19:23:15 | time:69747s total_exs:4749782 total_steps:350501 epochs:258.82 time_left:64996s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.05     1  4366 22984       0          0  1348 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    2.109    .3148 11.51 .6686 7.5e-06  2946 15511       0          0 1.951   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .8384     .3969               350501 7312 38495 5.268\n",
      "\n",
      "19:23:25 | time:69757s total_exs:4762582 total_steps:350551 epochs:259.51 time_left:64643s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.17     1  4395 21559       0          0  1256 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    2.125    .3148 11.55 .6621 7.5e-06  2956 14497       0          0 1.939   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .8394     .3970               350551 7351 36057 4.908\n",
      "\n",
      "19:23:35 | time:69767s total_exs:4775382 total_steps:350601 epochs:260.21 time_left:64292s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.07     1  4370 23142       0          0  1356 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    2.186    .2880 11.51 .6520 7.5e-06  2946 15597       0          0 1.919   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .8414     .4005               350601 7316 38738 5.298\n",
      "\n",
      "19:23:45 | time:69777s total_exs:4788182 total_steps:350651 epochs:260.91 time_left:63943s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.12     1  4383 21907       0          0  1280 12800             16712   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
      "    2.182    .3017 11.55 .6421 7.5e-06  2956 14773       0          0  1.9   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .8429     .4007               350651 7338 36680 5.001\n",
      "\n",
      "19:23:54 | time:69786s total_exs:4800982 total_steps:350701 epochs:261.61 time_left:63595s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "    17.1     1  4379 23006       0          0  1345 12800             32768   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    2.088    .3148 11.58 .6465 7.5e-06  2965 15579       0          0 1.909   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .8429     .4004               350701 7344 38585 5.258\n",
      "\n",
      "19:24:05 | time:69798s total_exs:4813782 total_steps:350751 epochs:262.30 time_left:63250s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "    17.1     1  4379 19962       0          0  1167 12800             32768   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
      "    2.121    .3290 11.56 .6315 7.5e-06  2961 13497       0          0 1.88   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .8455     .4010               350751 7339 33459 4.561\n",
      "\n",
      "19:24:15 | time:69807s total_exs:4826582 total_steps:350801 epochs:263.00 time_left:62906s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   16.99     1  4350 23201       0          0  1366 12800             32768   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    2.232    .3017 11.49 .6271 7.5e-06  2941 15689       0          0 1.872   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .8449     .4030               350801 7291 38891 5.337\n",
      "\n",
      "19:24:25 | time:69817s total_exs:4839382 total_steps:350851 epochs:263.70 time_left:62564s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.11     1  4381 21856       0          0  1277 12800             32768   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    2.128    .3017 11.51 .6173 7.5e-06  2946 14698       0          0 1.854   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .8471     .4045               350851 7327 36553 4.992\n",
      "\n",
      "19:24:34 | time:69827s total_exs:4852182 total_steps:350901 epochs:264.40 time_left:62223s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.15     1  4390 23023       0          0  1342 12800             32768   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    2.058    .3148 11.52 .6065 7.5e-06  2950 15470       0          0 1.834   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .8488     .4048               350901 7341 38493 5.247\n",
      "\n",
      "19:24:45 | time:69837s total_exs:4864982 total_steps:350951 epochs:265.09 time_left:61885s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.08     1  4373 21666       0          0  1268 12800             32768   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    2.074    .3291 11.56 .5999 7.5e-06  2959 14663       0          0 1.822   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .8511     .4055               350951 7332 36329 4.958\n",
      "\n",
      "19:24:54 | time:69846s total_exs:4877782 total_steps:351001 epochs:265.79 time_left:61547s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.05     1  4365 23029       0          0  1351 12800             32768   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    2.156    .3148 11.52 .5937 7.5e-06  2949 15559       0          0 1.811   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .8506     .4014               351001 7314 38589 5.279\n",
      "\n",
      "19:25:05 | time:69858s total_exs:4890582 total_steps:351051 epochs:266.49 time_left:61213s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.05     1  4364 19691       0          0  1155 12800             32768   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
      "     2.22    .3148 11.54 .5876 7.5e-06  2954 13327       0          0  1.8   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .8511     .4015               351051 7318 33018 4.515\n",
      "\n",
      "19:25:15 | time:69867s total_exs:4903382 total_steps:351101 epochs:267.19 time_left:60880s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.04     1  4363 22743       0          0  1334 12800             32768   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    2.136    .3290 11.53 .5871 7.5e-06  2952 15389       0          0 1.799   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .8523     .4043               351101 7315 38132 5.216\n",
      "\n",
      "19:25:25 | time:69877s total_exs:4916182 total_steps:351151 epochs:267.88 time_left:60548s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.04     1  4361 21723       0          0  1275 12800             32768   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    2.049    .3290 11.52 .5752 7.5e-06  2950 14696       0          0 1.778   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .8542     .4084               351151 7311 36419 4.984\n",
      "\n",
      "19:25:34 | time:69887s total_exs:4928982 total_steps:351201 epochs:268.58 time_left:60217s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.03     1  4360 23129       0          0  1358 12800             32768   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    2.005    .3017 11.51 .5683 7.5e-06  2946 15628       0          0 1.765   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .8566     .4085               351201 7306 38757 5.309\n",
      "\n",
      "19:25:45 | time:69897s total_exs:4941782 total_steps:351251 epochs:269.28 time_left:59889s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.07     1  4369 21569       0          0  1264 12800             32768   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    2.003    .3148 11.54 .5685 7.5e-06  2954 14581       0          0 1.766   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .8559     .4072               351251 7323 36150 4.939\n",
      "\n",
      "19:25:54 | time:69907s total_exs:4954582 total_steps:351301 epochs:269.98 time_left:59562s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.15     1  4389 22808       0          0  1330 12800             26870   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "      inf    .3148 11.51 .5588 7.5e-06  2947 15315       0          0 1.749   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .8568     .4097               351301 7337 38123 5.199\n",
      "\n",
      "19:26:05 | time:69918s total_exs:4967382 total_steps:351351 epochs:270.67 time_left:59238s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.12     1  4384 19779       0          0  1155 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    1.981    .3148 11.52 .5566 7.5e-06  2950 13310       0          0 1.745   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .8574     .4115               351351 7334 33089 4.514\n",
      "\n",
      "19:26:15 | time:69927s total_exs:4980182 total_steps:351401 epochs:271.37 time_left:58914s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "    17.1     1  4378 22684       0          0  1326 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    2.034    .3148 11.49 .5392 7.5e-06  2940 15233       0          0 1.715   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .8606     .4080               351401 7319 37917 5.184\n",
      "\n",
      "19:26:25 | time:69937s total_exs:4992982 total_steps:351451 epochs:272.07 time_left:58592s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.02     1  4356 21816       0          0  1282 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    2.036    .3291 11.46 .5407 7.5e-06  2935 14697       0          0 1.717   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .8602     .4083               351451 7291 36513 5.011\n",
      "\n",
      "19:26:35 | time:69947s total_exs:5005782 total_steps:351501 epochs:272.76 time_left:58271s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   16.98     1  4347 22785       0          0  1342 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "     2.08    .3017 11.53 .5300 7.5e-06  2951 15465       0          0 1.699   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .8615     .4080               351501 7298 38250 5.244\n",
      "\n",
      "19:26:45 | time:69957s total_exs:5018582 total_steps:351551 epochs:273.46 time_left:57953s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "    17.1     1  4377 21763       0          0  1273 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
      "    2.048    .3148 11.51 .5364 7.5e-06  2945 14643       0          0 1.71   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .8620     .4080               351551 7323 36406 4.975\n",
      "\n",
      "19:26:54 | time:69967s total_exs:5031382 total_steps:351601 epochs:274.16 time_left:57635s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.03     1  4360 22847       0          0  1341 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    2.086    .3290 11.49 .5297 7.5e-06  2942 15419       0          0 1.698   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .8630     .4105               351601 7302 38265 5.243\n",
      "\n",
      "19:27:01 | saving model checkpoint: /home/yacine_zahidi_orange_com/envs/general-env39/lib/python3.9/site-packages/data/models/blender/blender_90M/model.checkpoint\n",
      "19:27:08 | time:69981s total_exs:5044182 total_steps:351651 epochs:274.86 time_left:57323s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   16.99     1  4348 15741       0          0 926.7 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    2.025    .3290 11.51 .5206 7.5e-06  2948 10671       0          0 1.683   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .8639     .4093               351651 7296 26413 3.622\n",
      "\n",
      "19:27:18 | time:69990s total_exs:5056982 total_steps:351701 epochs:275.55 time_left:57008s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.12     1  4383 22887       0          0  1337 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
      "    2.033    .3291 11.52 .5126 7.5e-06  2949 15399       0          0 1.67   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .8661     .4159               351701 7332 38286 5.224\n",
      "\n",
      "19:27:28 | time:70000s total_exs:5069782 total_steps:351751 epochs:276.25 time_left:56696s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.16     1  4394 22000       0          0  1282 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "     1.94    .3017 11.55 .5075 7.5e-06  2956 14802       0          0 1.661   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps  ups  \n",
      "        .8678     .4157               351751 7350 36802 5.01\n",
      "\n",
      "19:27:37 | time:70010s total_exs:5082582 total_steps:351801 epochs:276.95 time_left:56385s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.09     1  4376 23116       0          0  1352 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    1.961    .3017 11.52 .5036 7.5e-06  2948 15574       0          0 1.655   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .8689     .4131               351801 7324 38690 5.286\n",
      "\n",
      "19:27:47 | time:70020s total_exs:5095382 total_steps:351851 epochs:277.65 time_left:56075s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   16.99     1  4351 21853       0          0  1286 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    2.018    .3017 11.48 .4953 7.5e-06  2939 14761       0          0 1.641   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .8687     .4142               351851 7289 36614 5.026\n",
      "\n",
      "19:27:57 | time:70029s total_exs:5108182 total_steps:351901 epochs:278.34 time_left:55767s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.14     1  4388 22875       0          0  1335 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    2.046    .3148  11.5 .4901 7.5e-06  2944 15351       0          0 1.632   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .8702     .4121               351901 7332 38226 5.217\n",
      "\n",
      "19:28:08 | time:70041s total_exs:5120982 total_steps:351951 epochs:279.04 time_left:55461s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.06     1  4368 19881       0          0  1165 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    2.066    .3290 11.52 .4879 7.5e-06  2950 13425       0          0 1.629   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .8701     .4176               351951 7318 33306 4.554\n",
      "\n",
      "19:28:18 | time:70050s total_exs:5133782 total_steps:352001 epochs:279.74 time_left:55156s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.12     1  4383 22933       0          0  1339 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    2.015    .3291 11.54 .4856 7.5e-06  2955 15463       0          0 1.625   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .8722     .4167               352001 7339 38396 5.235\n",
      "\n",
      "19:28:28 | time:70060s total_exs:5146582 total_steps:352051 epochs:280.44 time_left:54852s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.05     1  4365 21945       0          0  1287 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
      "    1.977    .3017 11.57 .4765 7.5e-06  2962 14891       0          0 1.61   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps  ups  \n",
      "        .8736     .4196               352051 7327 36836 5.03\n",
      "\n",
      "19:28:37 | time:70070s total_exs:5159382 total_steps:352101 epochs:281.13 time_left:54550s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "    17.1     1  4379 23006       0          0  1345 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    1.949    .3290 11.57 .4775 7.5e-06  2962 15562       0          0 1.612   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .8734     .4191               352101 7341 38568 5.257\n",
      "\n",
      "19:28:47 | time:70080s total_exs:5172182 total_steps:352151 epochs:281.83 time_left:54249s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.09     1  4374 22221       0          0  1301 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "     1.92    .3017 11.55 .4657 7.5e-06  2958 15025       0          0 1.593   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .8751     .4154               352151 7331 37245 5.083\n",
      "\n",
      "19:28:57 | time:70089s total_exs:5184982 total_steps:352201 epochs:282.53 time_left:53949s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.07     1  4369 22994       0          0  1347 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    1.941    .3148 11.53 .4612 7.5e-06  2951 15532       0          0 1.586   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .8758     .4191               352201 7320 38527 5.266\n",
      "\n",
      "19:29:08 | time:70100s total_exs:5197782 total_steps:352251 epochs:283.23 time_left:53652s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.03     1  4361 20329       0          0  1193 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    1.937    .3017 11.49 .4602 7.5e-06  2942 13714       0          0 1.584   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .8773     .4240               352251 7302 34043 4.664\n",
      "\n",
      "19:29:17 | time:70109s total_exs:5210582 total_steps:352301 epochs:283.92 time_left:53355s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.07     1  4371 23246       0          0  1362 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    1.928    .3148 11.53 .4570 7.5e-06  2953 15705       0          0 1.579   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .8775     .4206               352301 7323 38951 5.322\n",
      "\n",
      "19:29:27 | time:70119s total_exs:5223382 total_steps:352351 epochs:284.62 time_left:53060s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.09     1  4376 22169       0          0  1297 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "     1.96    .3148 11.52 .4556 7.5e-06  2948 14937       0          0 1.577   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .8781     .4164               352351 7324 37106 5.069\n",
      "\n",
      "19:29:37 | time:70129s total_exs:5236182 total_steps:352401 epochs:285.32 time_left:52766s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.14     1  4387 23096       0          0  1348 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    1.912    .3148 11.57 .4534 7.5e-06  2961 15587       0          0 1.574   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .8784     .4180               352401 7348 38682 5.268\n",
      "\n",
      "19:29:47 | time:70139s total_exs:5248982 total_steps:352451 epochs:286.02 time_left:52474s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   16.99     1  4349 21875       0          0  1288 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    1.996    .3291  11.5 .4421 7.5e-06  2944 14806       0          0 1.556   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .8804     .4197               352451 7293 36681 5.033\n",
      "\n",
      "19:29:56 | time:70148s total_exs:5261782 total_steps:352501 epochs:286.71 time_left:52183s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.02     1  4356 22864       0          0  1344 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    2.044    .3291 11.54 .4377 7.5e-06  2955 15512       0          0 1.549   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .8814     .4178               352501 7311 38376 5.252\n",
      "\n",
      "19:30:07 | time:70159s total_exs:5274582 total_steps:352551 epochs:287.41 time_left:51894s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.15     1  4391 19967       0          0  1164 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    2.482    .3291  11.6 .4361 7.5e-06  2970 13504       0          0 1.547   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .8810     .4233               352551 7361 33471 4.549\n",
      "\n",
      "19:30:17 | time:70169s total_exs:5287382 total_steps:352601 epochs:288.11 time_left:51606s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.08     1  4372 23283       0          0  1363 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    1.928    .3148 11.56 .4305 7.5e-06  2959 15760       0          0 1.538   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .8831     .4219               352601 7331 39043 5.329\n",
      "\n",
      "19:30:27 | time:70179s total_exs:5300182 total_steps:352651 epochs:288.81 time_left:51319s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.04     1  4361 22013       0          0  1292 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    1.884    .3291 11.54 .4264 7.5e-06  2955 14918       0          0 1.532   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .8831     .4234               352651 7316 36931 5.051\n",
      "\n",
      "19:30:36 | time:70188s total_exs:5312982 total_steps:352701 epochs:289.50 time_left:51033s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.11     1  4381 23144       0          0  1352 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    1.906    .3291 11.53 .4280 7.5e-06  2952 15596       0          0 1.534   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .8834     .4278               352701 7333 38740 5.286\n",
      "\n",
      "19:30:47 | time:70199s total_exs:5325782 total_steps:352751 epochs:290.20 time_left:50750s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.07     1  4369 20734       0          0  1215 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    1.955    .3291 11.52 .4207 7.5e-06  2948 13991       0          0 1.523   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .8851     .4225               352751 7317 34726 4.748\n",
      "\n",
      "19:30:56 | time:70209s total_exs:5338582 total_steps:352801 epochs:290.90 time_left:50466s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.02     1  4357 22907       0          0  1346 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    1.899    .3017 11.51 .4159 7.5e-06  2947 15497       0          0 1.516   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .8859     .4253               352801 7304 38404 5.261\n",
      "\n",
      "19:31:07 | time:70220s total_exs:5351382 total_steps:352851 epochs:291.60 time_left:50186s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.03     1  4360 19751       0          0  1160 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    1.887    .3148 11.51 .4133 7.5e-06  2946 13348       0          0 1.512   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .8857     .4241               352851 7306 33099 4.533\n",
      "\n",
      "19:31:17 | time:70229s total_exs:5364182 total_steps:352901 epochs:292.29 time_left:49905s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.05     1  4365 23170       0          0  1359 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    1.897    .3290 11.48 .4087 7.5e-06  2939 15602       0          0 1.505   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .8872     .4218               352901 7304 38772 5.312\n",
      "\n",
      "19:31:27 | time:70239s total_exs:5376982 total_steps:352951 epochs:292.99 time_left:49626s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.11     1  4380 22005       0          0  1286 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    1.923    .3148 11.53 .4063 7.5e-06  2952 14833       0          0 1.501   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .8872     .4263               352951 7332 36838 5.027\n",
      "\n",
      "19:31:36 | time:70249s total_exs:5389782 total_steps:353001 epochs:293.69 time_left:49348s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "    17.1     1  4377 23294       0          0  1362 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
      "    2.039    .3148 11.56 .4057 7.5e-06  2958 15743       0          0  1.5   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .8881     .4270               353001 7335 39037 5.325\n",
      "\n",
      "19:31:46 | time:70259s total_exs:5402582 total_steps:353051 epochs:294.39 time_left:49072s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.08     1  4373 21950       0          0  1285 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "     1.88    .3290 11.52 .3996 7.5e-06  2950 14810       0          0 1.491   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .8890     .4249               353051 7323 36760 5.023\n",
      "\n",
      "19:31:56 | time:70268s total_exs:5415382 total_steps:353101 epochs:295.08 time_left:48796s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.09     1  4375 23457       0          0  1373 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    1.879    .3148  11.5 .3896 7.5e-06  2943 15780       0          0 1.476   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .8913     .4298               353101 7318 39237 5.365\n",
      "\n",
      "19:32:07 | time:70279s total_exs:5428182 total_steps:353151 epochs:295.78 time_left:48523s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.14     1  4388 20226       0          0  1180 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    1.873    .3148 11.57 .3906 7.5e-06  2962 13651       0          0 1.478   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .8895     .4271               353151 7350 33877 4.612\n",
      "\n",
      "19:32:16 | time:70288s total_exs:5440982 total_steps:353201 epochs:296.48 time_left:48250s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.23     1  4411 23383       0          0  1357 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    1.856    .3148 11.58 .3879 7.5e-06  2964 15711       0          0 1.474   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .8920     .4308               353201 7374 39094 5.304\n",
      "\n",
      "19:32:26 | time:70298s total_exs:5453782 total_steps:353251 epochs:297.18 time_left:47979s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.08     1  4372 21813       0          0  1277 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    1.901    .3291  11.5 .3876 7.5e-06  2945 14693       0          0 1.474   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .8923     .4307               353251 7318 36506 4.992\n",
      "\n",
      "19:32:35 | time:70308s total_exs:5466582 total_steps:353301 epochs:297.87 time_left:47708s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.13     1  4386 23462       0          0  1369 12800             22282   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    2.084    .3148 11.56 .3831 7.5e-06  2959 15828       0          0 1.467   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .8927     .4318               353301 7345 39291 5.352\n",
      "\n",
      "19:32:46 | time:70318s total_exs:5479382 total_steps:353351 epochs:298.57 time_left:47439s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.07     1  4370 21877       0          0  1281 12800             32768   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    1.854    .3148 11.52 .3748 7.5e-06  2949 14764       0          0 1.455   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .8939     .4248               353351 7320 36641 5.009\n",
      "\n",
      "19:32:55 | time:70327s total_exs:5492182 total_steps:353401 epochs:299.27 time_left:47171s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.11     1  4379 23276       0          0  1361 12800             32768   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "     2.37    .3017 11.58 .3740 7.5e-06  2965 15759       0          0 1.454   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .8949     .4298               353401 7344 39034 5.319\n",
      "\n",
      "19:33:06 | time:70338s total_exs:5504982 total_steps:353451 epochs:299.97 time_left:46905s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.03     1  4359 20141       0          0  1183 12800             32768   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    1.914    .3148 11.46 .3732 7.5e-06  2933 13551       0          0 1.452   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .8934     .4295               353451 7292 33693 4.623\n",
      "\n",
      "19:33:15 | time:70347s total_exs:5517782 total_steps:353501 epochs:300.66 time_left:46639s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.05     1  4365 23511       0          0  1379 12800             32768   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    1.936    .3017 11.52 .3677 7.5e-06  2949 15884       0          0 1.444   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .8964     .4336               353501 7315 39396 5.389\n",
      "\n",
      "19:33:25 | time:70357s total_exs:5530582 total_steps:353551 epochs:301.36 time_left:46375s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.04     1  4361 22067       0          0  1295 12800             32768   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    1.892    .3291 11.51 .3666 7.5e-06  2946 14905       0          0 1.443   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .8961     .4318               353551 7307 36973 5.063\n",
      "\n",
      "19:33:34 | time:70367s total_exs:5543382 total_steps:353601 epochs:302.06 time_left:46112s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   16.97     1  4344 23440       0          0  1381 12800             32768   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
      "     1.85    .3017 11.44 .3644 7.5e-06  2928 15797       0          0 1.44   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .8955     .4293               353601 7271 39237 5.399\n",
      "\n",
      "19:33:45 | time:70377s total_exs:5556182 total_steps:353651 epochs:302.76 time_left:45850s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.06     1  4368 21718       0          0  1273 12800             32768   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    1.814    .3148 11.52 .3617 7.5e-06  2949 14664       0          0 1.436   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .8965     .4368               353651 7317 36383 4.975\n",
      "\n",
      "19:33:54 | time:70386s total_exs:5568982 total_steps:353701 epochs:303.45 time_left:45589s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.14     1  4387 23407       0          0  1366 12800             32768   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    1.809    .3017 11.54 .3545 7.5e-06  2955 15768       0          0 1.426   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .8988     .4365               353701 7343 39176 5.338\n",
      "\n",
      "19:34:05 | time:70397s total_exs:5581782 total_steps:353751 epochs:304.15 time_left:45330s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.04     1  4363 20298       0          0  1191 12800             32768   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    1.813    .3290  11.5 .3546 7.5e-06  2945 13699       0          0 1.426   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .8980     .4319               353751 7308 33997 4.655\n",
      "\n",
      "19:34:14 | time:70406s total_exs:5594582 total_steps:353801 epochs:304.85 time_left:45071s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.02     1  4357 23136       0          0  1359 12800             32768   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    1.857    .3291 11.46 .3558 7.5e-06  2935 15582       0          0 1.427   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .8979     .4359               353801 7292 38718 5.313\n",
      "\n",
      "19:34:24 | time:70416s total_exs:5607382 total_steps:353851 epochs:305.55 time_left:44814s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.06     1  4366 21931       0          0  1286 12800             32768   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    1.836    .3017 11.58 .3466 7.5e-06  2964 14886       0          0 1.414   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .9012     .4370               353851 7330 36818 5.026\n",
      "\n",
      "19:34:34 | time:70426s total_exs:5620182 total_steps:353901 epochs:306.24 time_left:44558s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.11     1  4380 22997       0          0  1344 12800             32768   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    1.791    .3148 11.55 .3467 7.5e-06  2957 15525       0          0 1.414   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .9004     .4374               353901 7338 38522 5.317\n",
      "\n",
      "19:34:44 | time:70436s total_exs:5632982 total_steps:353951 epochs:306.94 time_left:44303s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   16.95     1  4340 22025       0          0  1299 12800             32768   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    1.951    .3148 11.46 .3461 7.5e-06  2933 14886       0          0 1.413   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .9010     .4370               353951 7273 36912 5.078\n",
      "\n",
      "19:34:53 | time:70445s total_exs:5645782 total_steps:354001 epochs:307.64 time_left:44048s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.11     1  4380 23312       0          0  1362 12800             32768   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    1.816    .3148 11.59 .3400 7.5e-06  2967 15792       0          0 1.405   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .9017     .4368               354001 7348 39104 5.325\n",
      "\n",
      "19:35:04 | time:70456s total_exs:5658582 total_steps:354051 epochs:308.34 time_left:43796s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.02     1  4357 20092       0          0  1181 12800             32768   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    1.889    .3148 11.53 .3386 7.5e-06  2952 13614       0          0 1.403   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .9022     .4317               354051 7309 33706 4.614\n",
      "\n",
      "19:35:13 | time:70466s total_exs:5671382 total_steps:354101 epochs:309.03 time_left:43544s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.16     1  4392 23412       0          0  1365 12800             32768   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    1.914    .3148 11.55 .3389 7.5e-06  2956 15756       0          0 1.403   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .9015     .4387               354101 7348 39168 5.334\n",
      "\n",
      "19:35:23 | time:70476s total_exs:5684182 total_steps:354151 epochs:309.73 time_left:43294s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.18     1  4397 22067       0          0  1285 12800             32768   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    1.818    .3148 11.57 .3329 7.5e-06  2962 14865       0          0 1.395   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .9030     .4417               354151 7360 36931 5.021\n",
      "\n",
      "19:35:33 | time:70485s total_exs:5696982 total_steps:354201 epochs:310.43 time_left:43044s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.16     1  4392 23083       0          0  1345 12800             32768   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    2.001    .3290 11.54 .3304 7.5e-06  2955 15532       0          0 1.391   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .9038     .4415               354201 7347 38615 5.259\n",
      "\n",
      "19:35:43 | time:70495s total_exs:5709782 total_steps:354251 epochs:311.13 time_left:42795s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.05     1  4365 22010       0          0  1291 12800             32768   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    1.987    .3148 11.51 .3300 7.5e-06  2946 14856       0          0 1.391   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .9037     .4378               354251 7311 36866 5.045\n",
      "\n",
      "19:35:52 | time:70505s total_exs:5722582 total_steps:354301 epochs:311.82 time_left:42548s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.06     1  4368 23378       0          0  1370 12800             28180   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "      inf    .3148 11.58 .3305 7.5e-06  2965 15872       0          0 1.392   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .9041     .4375               354301 7333 39250 5.356\n",
      "\n",
      "19:36:04 | time:70516s total_exs:5735382 total_steps:354351 epochs:312.52 time_left:42302s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.11     1  4381 19544       0          0  1142 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    1.809    .3017  11.5 .3261 7.5e-06  2945 13139       0          0 1.386   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .9052     .4422               354351 7326 32684 4.464\n",
      "\n",
      "19:36:13 | time:70525s total_exs:5748182 total_steps:354401 epochs:313.22 time_left:42056s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.13     1  4386 23661       0          0  1381 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    1.747    .3148 11.52 .3250 7.5e-06  2950 15914       0          0 1.384   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .9054     .4424               354401 7335 39574 5.399\n",
      "\n",
      "19:36:23 | time:70535s total_exs:5760982 total_steps:354451 epochs:313.92 time_left:41812s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.17     1  4394 22122       0          0  1289 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    1.789    .3290 11.54 .3200 7.5e-06  2954 14869       0          0 1.377   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .9058     .4416               354451 7348 36991 5.037\n",
      "\n",
      "19:36:32 | time:70545s total_exs:5773782 total_steps:354501 epochs:314.61 time_left:41569s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.15     1  4390 23285       0          0  1358 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    2.094    .3017 11.61 .3177 7.5e-06  2971 15761       0          0 1.374   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .9070     .4422               354501 7361 39046 5.307\n",
      "\n",
      "19:36:42 | time:70555s total_exs:5786582 total_steps:354551 epochs:315.31 time_left:41326s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.11     1  4381 22229       0          0  1299 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    1.766    .3148 11.51 .3125 7.5e-06  2948 14957       0          0 1.367   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .9077     .4416               354551 7328 37185 5.077\n",
      "\n",
      "19:36:52 | time:70564s total_exs:5799382 total_steps:354601 epochs:316.01 time_left:41085s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.03     1  4359 23318       0          0  1369 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    1.825    .3148 11.53 .3161 7.5e-06  2952 15790       0          0 1.372   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .9073     .4449               354601 7311 39108 5.353\n",
      "\n",
      "19:37:04 | time:70576s total_exs:5812182 total_steps:354651 epochs:316.71 time_left:40846s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.19     1  4400 18348       0          0  1067 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    1.868    .3290 11.58 .3096 7.5e-06  2964 12357       0          0 1.363   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .9089     .4473               354651 7364 30706 4.173\n",
      "\n",
      "19:37:04 | saving model checkpoint: /home/yacine_zahidi_orange_com/envs/general-env39/lib/python3.9/site-packages/data/models/blender/blender_90M/model.checkpoint\n",
      "19:37:17 | time:70589s total_exs:5824982 total_steps:354701 epochs:317.40 time_left:40609s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.04     1  4363 16995       0          0 997.2 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "     1.83    .3017 11.47 .3094 7.5e-06  2937 11442       0          0 1.363   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .9083     .4405               354701 7300 28437 3.897\n",
      "\n",
      "19:37:27 | time:70599s total_exs:5837782 total_steps:354751 epochs:318.10 time_left:40371s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.11     1  4381 21347       0          0  1247 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    1.763    .3148 11.52 .3090 7.5e-06  2948 14364       0          0 1.362   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .9084     .4442               354751 7329 35710 4.875\n",
      "\n",
      "19:37:36 | time:70609s total_exs:5850582 total_steps:354801 epochs:318.80 time_left:40133s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.06     1  4368 23473       0          0  1376 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    1.779    .3148 11.48 .3025 7.5e-06  2938 15789       0          0 1.353   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .9097     .4455               354801 7306 39262 5.377\n",
      "\n",
      "19:37:46 | time:70619s total_exs:5863382 total_steps:354851 epochs:319.50 time_left:39897s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.16     1  4392 21852       0          0  1274 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    1.791    .3148 11.56 .3029 7.5e-06  2960 14725       0          0 1.354   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .9103     .4453               354851 7352 36578 4.978\n",
      "\n",
      "19:37:56 | time:70628s total_exs:5876182 total_steps:354901 epochs:320.19 time_left:39662s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.04     1  4362 23125       0          0  1357 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    1.774    .3148 11.53 .3013 7.5e-06  2952 15654       0          0 1.352   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .9097     .4432               354901 7314 38779 5.305\n",
      "\n",
      "19:38:07 | time:70639s total_exs:5888982 total_steps:354951 epochs:320.89 time_left:39428s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "    17.1     1  4377 20284       0          0  1186 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    1.729    .3148 11.53 .2952 7.5e-06  2952 13681       0          0 1.343   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .9111     .4486               354951 7329 33965 4.636\n",
      "\n",
      "19:38:16 | time:70649s total_exs:5901782 total_steps:355001 epochs:321.59 time_left:39195s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "    17.1     1  4377 22870       0          0  1337 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    1.908    .3148 11.58 .2973 7.5e-06  2964 15488       0          0 1.346   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .9111     .4459               355001 7342 38358 5.228\n",
      "\n",
      "19:38:27 | time:70659s total_exs:5914582 total_steps:355051 epochs:322.29 time_left:38963s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.09 .9800  4376 21175       0          0  1239 12800             12943   \n",
      "    gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "      .3148 11.59 .2945 7.5e-06  2967 14357       0          0 1.342   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .9117     .4462               355051 7343 35533 4.843\n",
      "\n",
      "19:38:37 | time:70669s total_exs:5927382 total_steps:355101 epochs:322.98 time_left:38731s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.03     1  4360 22279       0          0  1308 12800              8192   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "     1.98    .3290 11.46 .2933 7.5e-06  2934 14994       0          0 1.341   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .9119     .4450               355101 7294 37273 5.113\n",
      "\n",
      "19:38:47 | time:70679s total_exs:5940182 total_steps:355151 epochs:323.68 time_left:38501s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.04     1  4362 21498       0          0  1262 12800              8192   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    1.817    .3290 11.49 .2955 7.5e-06  2942 14500       0          0 1.344   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .9113     .4487               355151 7304 35998 4.931\n",
      "\n",
      "19:38:56 | time:70689s total_exs:5952982 total_steps:355201 epochs:324.38 time_left:38272s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "    17.2     1  4403 23428       0          0  1362 12800              8192   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    1.809    .3148 11.53 .2865 7.5e-06  2952 15710       0          0 1.332   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .9122     .4513               355201 7356 39138 5.324\n",
      "\n",
      "19:39:07 | time:70700s total_exs:5965782 total_steps:355251 epochs:325.08 time_left:38044s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.05     1  4366 19830       0          0  1163 12800              8192   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    1.801    .3148 11.53 .2879 7.5e-06  2951 13404       0          0 1.334   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .9134     .4468               355251 7317 33233 4.544\n",
      "\n",
      "19:39:17 | time:70709s total_exs:5978582 total_steps:355301 epochs:325.77 time_left:37816s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.09     1  4376 22267       0          0  1303 12800              8192   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    1.692    .3017 11.52 .2877 7.5e-06  2949 15003       0          0 1.333   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .9117     .4468               355301 7325 37270 5.091\n",
      "\n",
      "19:39:27 | time:70719s total_exs:5991382 total_steps:355351 epochs:326.47 time_left:37590s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.11     1  4381 22060       0          0  1289 12800              8192   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    1.836    .2880 11.49 .2863 7.5e-06  2942 14816       0          0 1.332   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .9127     .4463               355351 7324 36876 5.038\n",
      "\n",
      "19:39:37 | time:70729s total_exs:6004182 total_steps:355401 epochs:327.17 time_left:37364s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "    17.1     1  4376 23068       0          0  1349 12800              8192   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    1.796    .3148 11.51 .2865 7.5e-06  2945 15525       0          0 1.332   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .9137     .4484               355401 7322 38592 5.274\n",
      "\n",
      "19:39:47 | time:70739s total_exs:6016982 total_steps:355451 epochs:327.87 time_left:37139s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.13     1  4386 21820       0          0  1274 12800              8192   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "     1.69    .3148 11.56 .2795 7.5e-06  2959 14719       0          0 1.323   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .9160     .4520               355451 7344 36540 4.978\n",
      "\n",
      "19:39:56 | time:70748s total_exs:6029782 total_steps:355501 epochs:328.56 time_left:36915s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.07     1  4369 23676       0          0  1387 12800              8192   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    1.744    .3017 11.51 .2798 7.5e-06  2945 15962       0          0 1.323   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .9143     .4516               355501 7314 39638 5.422\n",
      "\n",
      "19:40:07 | time:70759s total_exs:6042582 total_steps:355551 epochs:329.26 time_left:36693s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.03     1  4360 20172       0          0  1184 12800              8192   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    1.692    .3017 11.52 .2765 7.5e-06  2950 13646       0          0 1.319   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .9155     .4498               355551 7310 33818 4.629\n",
      "\n",
      "19:40:16 | time:70769s total_exs:6055382 total_steps:355601 epochs:329.96 time_left:36470s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.07     1  4370 23435       0          0  1373 12800              8192   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    1.676    .3148 11.51 .2766 7.5e-06  2946 15800       0          0 1.319   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .9153     .4478               355601 7316 39235 5.366\n",
      "\n",
      "19:40:26 | time:70779s total_exs:6068182 total_steps:355651 epochs:330.66 time_left:36249s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.15     1  4390 22305       0          0  1301 12800              8192   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "     1.79    .3291 11.55 .2720 7.5e-06  2956 15021       0          0 1.313   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .9170     .4530               355651 7346 37326 5.084\n",
      "\n",
      "19:40:36 | time:70788s total_exs:6080982 total_steps:355701 epochs:331.35 time_left:36029s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.04     1  4362 22591       0          0  1326 12800              8192   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    1.689    .3017 11.55 .2744 7.5e-06  2956 15310       0          0 1.316   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .9164     .4505               355701 7318 37901 5.182\n",
      "\n",
      "19:40:46 | time:70798s total_exs:6093782 total_steps:355751 epochs:332.05 time_left:35810s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "    17.1     1  4377 22196       0          0  1298 12800              8192   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    1.692    .3148 11.55 .2739 7.5e-06  2956 14993       0          0 1.315   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .9157     .4523               355751 7333 37189 5.075\n",
      "\n",
      "19:40:55 | time:70808s total_exs:6106582 total_steps:355801 epochs:332.75 time_left:35591s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.06     1  4368 23198       0          0  1359 12800              8192   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    1.933    .3017 11.46 .2712 7.5e-06  2932 15573       0          0 1.311   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .9163     .4530               355801 7301 38771 5.313\n",
      "\n",
      "19:41:06 | time:70819s total_exs:6119382 total_steps:355851 epochs:333.44 time_left:35374s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.11     1  4380 20024       0          0  1170 12800              8192   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    1.695    .3148 11.53 .2664 7.5e-06  2950 13488       0          0 1.305   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .9175     .4559               355851 7331 33512 4.574\n",
      "\n",
      "19:41:16 | time:70828s total_exs:6132182 total_steps:355901 epochs:334.14 time_left:35157s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.09     1  4376 22751       0          0  1331 12800              8192   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    1.756    .3291 11.53 .2712 7.5e-06  2953 15352       0          0 1.312   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .9163     .4480               355901 7329 38102 5.202\n",
      "\n",
      "19:41:26 | time:70838s total_exs:6144982 total_steps:355951 epochs:334.84 time_left:34941s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.17     1  4395 22124       0          0  1289 12800              8192   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    1.634    .3148 11.63 .2634 7.5e-06  2976 14983       0          0 1.301   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .9194     .4574               355951 7371 37107 5.037\n",
      "\n",
      "19:41:35 | time:70848s total_exs:6157782 total_steps:356001 epochs:335.54 time_left:34726s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.11     1  4379 23554       0          0  1377 12800              8192   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    1.697    .3148 11.51 .2684 7.5e-06  2947 15851       0          0 1.308   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .9169     .4529               356001 7326 39405 5.381\n",
      "\n",
      "19:41:46 | time:70858s total_exs:6170582 total_steps:356051 epochs:336.23 time_left:34512s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.06     1  4366 20791       0          0  1219 12800              8192   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    1.718    .3291 11.55 .2647 7.5e-06  2956 14074       0          0 1.303   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .9176     .4558               356051 7322 34865 4.764\n",
      "\n",
      "19:41:55 | time:70868s total_exs:6183382 total_steps:356101 epochs:336.93 time_left:34298s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.15     1  4389 23087       0          0  1347 12800              8192   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "     1.74    .3017 11.55 .2601 7.5e-06  2956 15551       0          0 1.297   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .9191     .4546               356101 7346 38638 5.264\n",
      "\n",
      "19:42:07 | time:70879s total_exs:6196182 total_steps:356151 epochs:337.63 time_left:34087s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "    17.1     1  4377 19322       0          0  1130 12800              8192   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    1.848    .3148 11.55 .2606 7.5e-06  2956 13050       0          0 1.298   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .9187     .4581               356151 7333 32372 4.417\n",
      "\n",
      "19:42:17 | time:70889s total_exs:6208982 total_steps:356201 epochs:338.33 time_left:33875s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   16.99     1  4349 22500       0          0  1324 12800              8192   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    1.629    .3148  11.5 .2560 7.5e-06  2944 15228       0          0 1.292   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .9192     .4545               356201 7293 37728 5.176\n",
      "\n",
      "19:42:26 | time:70899s total_exs:6221782 total_steps:356251 epochs:339.02 time_left:33664s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.05     1  4366 22048       0          0  1293 12800              8192   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    1.717    .3148 11.55 .2577 7.5e-06  2957 14933       0          0 1.294   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .9189     .4537               356251 7322 36982 5.053\n",
      "\n",
      "19:42:36 | time:70908s total_exs:6234582 total_steps:356301 epochs:339.72 time_left:33454s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.03     1  4359 23467       0          0  1378 12800              8192   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    1.682    .3148 11.55 .2551 7.5e-06  2957 15919       0          0 1.291   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .9201     .4515               356301 7317 39386 5.386\n",
      "\n",
      "19:42:46 | time:70918s total_exs:6247382 total_steps:356351 epochs:340.42 time_left:33245s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.02     1  4356 21185       0          0  1245 12800              8192   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    1.699    .3017 11.48 .2526 7.5e-06  2938 14290       0          0 1.287   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .9203     .4555               356351 7294 35474 4.866\n",
      "\n",
      "19:42:56 | time:70928s total_exs:6260182 total_steps:356401 epochs:341.12 time_left:33036s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.02     1  4356 23387       0          0  1374 12800              8192   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    1.806    .3017  11.5 .2539 7.5e-06  2945 15809       0          0 1.289   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .9193     .4533               356401 7301 39196 5.372\n",
      "\n",
      "19:43:07 | time:70939s total_exs:6272982 total_steps:356451 epochs:341.81 time_left:32829s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.05     1  4366 19823       0          0  1162 12800              8192   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    1.632    .3148 11.48 .2504 7.5e-06  2939 13347       0          0 1.284   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .9206     .4570               356451 7305 33169 4.543\n",
      "\n",
      "19:43:16 | time:70948s total_exs:6285782 total_steps:356501 epochs:342.51 time_left:32622s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.12     1  4382 23316       0          0  1362 12800              8192   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    1.627    .3148 11.55 .2515 7.5e-06  2957 15733       0          0 1.286   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .9207     .4558               356501 7339 39048 5.323\n",
      "\n",
      "19:43:26 | time:70958s total_exs:6298582 total_steps:356551 epochs:343.21 time_left:32416s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "      17     1  4353 22022       0          0  1295 12800              8192   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    1.658    .3148  11.5 .2525 7.5e-06  2945 14897       0          0 1.287   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .9198     .4527               356551 7298 36919 5.062\n",
      "\n",
      "19:43:35 | time:70968s total_exs:6311382 total_steps:356601 epochs:343.91 time_left:32211s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.15     1  4390 23522       0          0  1372 12800              8192   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
      "    1.858    .3148 11.53 .2469 7.5e-06  2951 15815       0          0 1.28   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .9207     .4541               356601 7341 39337 5.362\n",
      "\n",
      "19:43:45 | time:70978s total_exs:6324182 total_steps:356651 epochs:344.60 time_left:32007s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "    17.1     1  4376 21906       0          0  1281 12800              8192   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    1.716    .3290 11.55 .2478 7.5e-06  2957 14801       0          0 1.281   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .9219     .4599               356651 7333 36707 5.008\n",
      "\n",
      "19:43:55 | time:70987s total_exs:6336982 total_steps:356701 epochs:345.30 time_left:31803s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.11     1  4380 23156       0          0  1353 12800              8192   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    1.638    .3148 11.53 .2444 7.5e-06  2952 15606       0          0 1.277   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .9219     .4596               356701 7333 38761 5.289\n",
      "\n",
      "19:44:06 | time:70998s total_exs:6349782 total_steps:356751 epochs:346.00 time_left:31600s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "    17.1     1  4377 20081       0          0  1175 12800              8192   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
      "    1.647    .3148  11.5 .2470 7.5e-06  2944 13507       0          0 1.28   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .9217     .4587               356751 7320 33588 4.591\n",
      "\n",
      "19:44:15 | time:71008s total_exs:6362582 total_steps:356801 epochs:346.70 time_left:31398s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.15     1  4391 23252       0          0  1356 12800              8192   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    1.671    .3148 11.56 .2444 7.5e-06  2958 15664       0          0 1.277   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .9221     .4606               356801 7349 38916 5.298\n",
      "\n",
      "19:44:25 | time:71018s total_exs:6375382 total_steps:356851 epochs:347.39 time_left:31197s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.15     1  4390 22219       0          0  1296 12800              8192   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    1.636    .3148 11.56 .2426 7.5e-06  2960 14981       0          0 1.275   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .9232     .4634               356851 7351 37200 5.064\n",
      "\n",
      "19:44:35 | time:71027s total_exs:6388182 total_steps:356901 epochs:348.09 time_left:30996s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.06     1  4367 23352       0          0  1369 12800              8192   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    1.596    .3290 11.51 .2421 7.5e-06  2946 15753       0          0 1.274   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps  ups  \n",
      "        .9221     .4619               356901 7314 39104 5.35\n",
      "\n",
      "19:44:45 | time:71037s total_exs:6400982 total_steps:356951 epochs:348.79 time_left:30797s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.14     1  4389 22283       0          0  1300 12800              8192   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    1.662    .3017 11.54 .2394 7.5e-06  2953 14995       0          0 1.271   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps  ups  \n",
      "        .9230     .4577               356951 7342 37279 5.08\n",
      "\n",
      "19:44:54 | time:71046s total_exs:6413782 total_steps:357001 epochs:349.49 time_left:30597s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.06     1  4369 23437       0          0  1373 12800              8192   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    1.608    .3148  11.5 .2382 7.5e-06  2943 15791       0          0 1.269   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .9234     .4597               357001 7312 39228 5.368\n",
      "\n",
      "19:45:05 | time:71057s total_exs:6426582 total_steps:357051 epochs:350.18 time_left:30400s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.14     1  4388 20022       0          0  1168 12800             11633   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
      "    1.724    .3017 11.56 .2393 7.5e-06  2959 13503       0          0 1.27   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .9227     .4609               357051 7347 33525 4.566\n",
      "\n",
      "19:45:14 | time:71067s total_exs:6439382 total_steps:357101 epochs:350.88 time_left:30202s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.08     1  4374 23445       0          0  1372 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    1.653    .3148 11.52 .2386 7.5e-06  2950 15813       0          0 1.269   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .9233     .4605               357101 7323 39258 5.364\n",
      "\n",
      "19:45:24 | time:71076s total_exs:6452182 total_steps:357151 epochs:351.58 time_left:30005s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.09     1  4375 22377       0          0  1309 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    1.743    .3017 11.48 .2384 7.5e-06  2940 15037       0          0 1.269   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .9233     .4645               357151 7315 37413 5.118\n",
      "\n",
      "19:45:34 | time:71086s total_exs:6464982 total_steps:357201 epochs:352.28 time_left:29809s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.18     1  4397 23207       0          0  1351 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    1.768    .3148 11.57 .2356 7.5e-06  2963 15637       0          0 1.266   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps  ups  \n",
      "        .9235     .4617               357201 7361 38844 5.28\n",
      "\n",
      "19:45:44 | time:71096s total_exs:6477782 total_steps:357251 epochs:352.97 time_left:29614s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.09     1  4375 22239       0          0  1301 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    1.788    .3017 11.54 .2331 7.5e-06  2953 15013       0          0 1.263   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .9243     .4648               357251 7328 37252 5.086\n",
      "\n",
      "19:45:53 | time:71105s total_exs:6490582 total_steps:357301 epochs:353.67 time_left:29419s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.09     1  4374 23305       0          0  1364 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    1.709    .3148  11.5 .2321 7.5e-06  2945 15692       0          0 1.261   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .9244     .4630               357301 7319 38997 5.331\n",
      "\n",
      "19:46:04 | time:71116s total_exs:6503382 total_steps:357351 epochs:354.37 time_left:29226s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.07     1  4370 19584       0          0  1147 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    1.566    .3148 11.49 .2299 7.5e-06  2941 13182       0          0 1.259   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .9250     .4623               357351 7311 32766 4.484\n",
      "\n",
      "19:46:14 | time:71126s total_exs:6516182 total_steps:357401 epochs:355.07 time_left:29033s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "    17.2     1  4402 23348       0          0  1358 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    1.625    .3148 11.62 .2297 7.5e-06  2976 15781       0          0 1.258   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .9254     .4662               357401 7378 39129 5.307\n",
      "\n",
      "19:46:24 | time:71136s total_exs:6528982 total_steps:357451 epochs:355.76 time_left:28840s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.07     1  4371 22013       0          0  1289 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    1.627    .3291 11.52 .2317 7.5e-06  2949 14855       0          0 1.261   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .9254     .4667               357451 7320 36869 5.039\n",
      "\n",
      "19:46:33 | time:71145s total_exs:6541782 total_steps:357501 epochs:356.46 time_left:28648s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.12     1  4382 23690       0          0  1384 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "     1.68    .3148 11.52 .2281 7.5e-06  2948 15937       0          0 1.256   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .9253     .4659               357501 7331 39628 5.409\n",
      "\n",
      "19:46:43 | time:71155s total_exs:6554582 total_steps:357551 epochs:357.16 time_left:28458s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.07     1  4369 22413       0          0  1313 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "     1.78    .3148 11.54 .2305 7.5e-06  2954 15151       0          0 1.259   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .9251     .4635               357551 7323 37564 5.132\n",
      "\n",
      "19:46:52 | time:71164s total_exs:6567382 total_steps:357601 epochs:357.86 time_left:28267s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   16.98     1  4347 23209       0          0  1367 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    1.787    .3148 11.46 .2286 7.5e-06  2933 15657       0          0 1.257   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .9250     .4612               357601 7280 38866 5.406\n",
      "\n",
      "19:47:03 | time:71176s total_exs:6580182 total_steps:357651 epochs:358.55 time_left:28078s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.04     1  4361 19482       0          0  1144 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    1.759    .3017 11.54 .2255 7.5e-06  2954 13197       0          0 1.253   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .9263     .4670               357651 7315 32680 4.471\n",
      "\n",
      "19:47:08 | saving model checkpoint: /home/yacine_zahidi_orange_com/envs/general-env39/lib/python3.9/site-packages/data/models/blender/blender_90M/model.checkpoint\n",
      "19:47:16 | time:71188s total_exs:6592982 total_steps:357701 epochs:359.25 time_left:27890s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.02     1  4358 17234       0          0  1012 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    1.639    .3148 11.49 .2280 7.5e-06  2941 11633       0          0 1.256   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .9254     .4607               357701 7299 28866 3.957\n",
      "\n",
      "19:47:26 | time:71198s total_exs:6605782 total_steps:357751 epochs:359.95 time_left:27702s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.07     1  4370 22446       0          0  1315 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "     1.63    .3148 11.53 .2255 7.5e-06  2951 15157       0          0 1.253   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps  ups  \n",
      "        .9260     .4629               357751 7321 37603 5.14\n",
      "\n",
      "19:47:35 | time:71207s total_exs:6618582 total_steps:357801 epochs:360.65 time_left:27515s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.07     1  4369 23946       0          0  1403 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    1.657    .3148 11.51 .2268 7.5e-06  2945 16142       0          0 1.255   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .9261     .4637               357801 7315 40088 5.484\n",
      "\n",
      "19:47:45 | time:71217s total_exs:6631382 total_steps:357851 epochs:361.34 time_left:27328s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.08     1  4374 22302       0          0  1305 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    1.612    .3017 11.51 .2218 7.5e-06  2946 15025       0          0 1.248   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .9267     .4627               357851 7320 37326 5.103\n",
      "\n",
      "19:47:54 | time:71227s total_exs:6644182 total_steps:357901 epochs:362.04 time_left:27141s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "    17.1     1  4378 23429       0          0  1370 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
      "    1.676    .3291 11.55 .2230 7.5e-06  2957 15826       0          0 1.25   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .9258     .4623               357901 7334 39255 5.355\n",
      "\n",
      "19:48:05 | time:71237s total_exs:6656982 total_steps:357951 epochs:362.74 time_left:26956s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.16     1  4394 20894       0          0  1217 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
      "    1.577    .3148 11.57 .2229 7.5e-06  2963 14091       0          0 1.25   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .9258     .4658               357951 7357 34984 4.758\n",
      "\n",
      "19:48:14 | time:71247s total_exs:6669782 total_steps:358001 epochs:363.44 time_left:26771s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.15     1  4390 23452       0          0  1368 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    1.593    .3148 11.55 .2200 7.5e-06  2957 15797       0          0 1.246   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .9262     .4652               358001 7347 39249 5.345\n",
      "\n",
      "19:48:24 | time:71256s total_exs:6682582 total_steps:358051 epochs:364.13 time_left:26587s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.03     1  4360 22555       0          0  1324 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    1.586    .3148 11.47 .2202 7.5e-06  2935 15183       0          0 1.246   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .9270     .4709               358051 7295 37738 5.176\n",
      "\n",
      "19:48:33 | time:71265s total_exs:6695382 total_steps:358101 epochs:364.83 time_left:26404s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.15     1  4390 24022       0          0  1401 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    1.647    .3017 11.54 .2180 7.5e-06  2954 16164       0          0 1.244   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .9269     .4680               358101 7344 40186 5.475\n",
      "\n",
      "19:48:43 | time:71275s total_exs:6708182 total_steps:358151 epochs:365.53 time_left:26221s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.03     1  4359 22446       0          0  1318 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    1.645    .3148 11.46 .2207 7.5e-06  2935 15109       0          0 1.247   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .9263     .4648               358151 7294 37555 5.152\n",
      "\n",
      "19:48:52 | time:71285s total_exs:6720982 total_steps:358201 epochs:366.23 time_left:26039s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   16.97     1  4344 23387       0          0  1378 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    1.742    .3148 11.52 .2206 7.5e-06  2950 15882       0          0 1.247   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .9261     .4638               358201 7294 39268 5.387\n",
      "\n",
      "19:49:04 | time:71296s total_exs:6733782 total_steps:358251 epochs:366.92 time_left:25858s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.05     1  4366 18986       0          0  1113 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    1.539    .3148 11.52 .2155 7.5e-06  2948 12821       0          0 1.241   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .9276     .4672               358251 7314 31807 4.353\n",
      "\n",
      "19:49:13 | time:71306s total_exs:6746582 total_steps:358301 epochs:367.62 time_left:25677s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.18     1  4397 23253       0          0  1354 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    1.567    .3017 11.56 .2169 7.5e-06  2960 15654       0          0 1.242   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .9279     .4690               358301 7358 38907 5.291\n",
      "\n",
      "19:49:23 | time:71315s total_exs:6759382 total_steps:358351 epochs:368.32 time_left:25497s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.14     1  4387 22572       0          0  1317 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    1.657    .3017 11.53 .2146 7.5e-06  2951 15186       0          0 1.239   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .9275     .4645               358351 7338 37758 5.149\n",
      "\n",
      "19:49:32 | time:71325s total_exs:6772182 total_steps:358401 epochs:369.02 time_left:25317s\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps   exs  fp16_loss_scalar  \\\n",
      "   17.05     1  4364 23551       0          0  1382 12800             16384   \n",
      "    gnorm  gpu_mem  llen  loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "    1.561    .3148 11.52 .2146 7.5e-06  2949 15916       0          0 1.239   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps  ups  \n",
      "        .9282     .4688               358401 7313 39467  5.4\n",
      "\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/yacine_zahidi_orange_com/envs/general-env39/bin/parlai\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/home/yacine_zahidi_orange_com/envs/general-env39/lib/python3.9/site-packages/parlai/__main__.py\", line 14, in main\n",
      "    superscript_main()\n",
      "  File \"/home/yacine_zahidi_orange_com/envs/general-env39/lib/python3.9/site-packages/parlai/core/script.py\", line 325, in superscript_main\n",
      "    return SCRIPT_REGISTRY[cmd].klass._run_from_parser_and_opt(opt, parser)\n",
      "  File \"/home/yacine_zahidi_orange_com/envs/general-env39/lib/python3.9/site-packages/parlai/core/script.py\", line 108, in _run_from_parser_and_opt\n",
      "    return script.run()\n",
      "  File \"/home/yacine_zahidi_orange_com/envs/general-env39/lib/python3.9/site-packages/parlai/scripts/train_model.py\", line 1060, in run\n",
      "    return self.train_loop.train()\n",
      "  File \"/home/yacine_zahidi_orange_com/envs/general-env39/lib/python3.9/site-packages/parlai/scripts/train_model.py\", line 1010, in train\n",
      "    for _train_log in self.train_steps():\n",
      "  File \"/home/yacine_zahidi_orange_com/envs/general-env39/lib/python3.9/site-packages/parlai/scripts/train_model.py\", line 917, in train_steps\n",
      "    world.parley()\n",
      "  File \"/home/yacine_zahidi_orange_com/envs/general-env39/lib/python3.9/site-packages/parlai/core/worlds.py\", line 880, in parley\n",
      "    batch_act = self.batch_act(agent_idx, batch_observations[agent_idx])\n",
      "  File \"/home/yacine_zahidi_orange_com/envs/general-env39/lib/python3.9/site-packages/parlai/core/worlds.py\", line 848, in batch_act\n",
      "    batch_actions = a.batch_act(batch_observation)\n",
      "  File \"/home/yacine_zahidi_orange_com/envs/general-env39/lib/python3.9/site-packages/parlai/core/torch_agent.py\", line 2239, in batch_act\n",
      "    output = self.train_step(batch)\n",
      "  File \"/home/yacine_zahidi_orange_com/envs/general-env39/lib/python3.9/site-packages/parlai/core/torch_generator_agent.py\", line 748, in train_step\n",
      "    self.zero_grad()\n",
      "  File \"/home/yacine_zahidi_orange_com/envs/general-env39/lib/python3.9/site-packages/parlai/core/torch_agent.py\", line 2401, in zero_grad\n",
      "    self.optimizer.zero_grad()\n",
      "  File \"/home/yacine_zahidi_orange_com/envs/general-env39/lib/python3.9/site-packages/parlai/utils/fp16.py\", line 283, in zero_grad\n",
      "    p32.grad.zero_()\n",
      "KeyboardInterrupt\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Waiting for W&B process to finish... \u001B[31m(failed 255).\u001B[0m Press Control-C to abort syncing.\n"
     ]
    }
   ],
   "source": [
    "# !parlai train_model -mf zoo:blender/blender_90M/model  --batchsize 256 --wandb-log True --task fromfile:parlaiformat --fromfile-datapath ./convai3data --fromfile-datatype-extension true --num-epochs 500 --gpu 0 --save-every-n-secs 600 --validation-every-n-steps 50 --eval-dynamic-batching full --text-truncate 128\n",
    "!parlai train_model -mf zoo:blender/blender_90M/model  --batchsize 256 --wandb-log True --task fromfile:parlaiformat --fromfile-datapath ./convai3data --fromfile-datatype-extension true --num-epochs 500 --gpu 0 --save-every-n-secs 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cf4f40e4-3885-4194-a588-871b741ba4d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## 18:48:25 | saving model checkpoint: /home/yacine_zahidi_orange_com/envs/general-env39/lib/python3.9/site-packages/data/models/blender/blender_90M/model.checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "88f18d2c-b7ce-4588-b7e5-d3e3092bd177",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !cp /home/yacine_zahidi_orange_com/envs/general-env39/lib/python3.9/site-packages/data/models/blender/blender_90M/model.checkpoint model_blender90M_finetuned358ep.checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0fc5b3bd-6c25-4d78-84a7-c037dcb7e455",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:53:48 | \u001B[33mOverriding opt[\"model_file\"] to /home/yacine_zahidi_orange_com/envs/general-env39/lib/python3.9/site-packages/data/models/blender/blender_90M/model.checkpoint (previously: /home/yacine_zahidi_orange_com/envs/general-env39/lib/python3.9/site-packages/data/models/blender/blender_90M/model)\u001B[0m\n",
      "19:53:48 | Using CUDA\n",
      "19:53:48 | loading dictionary from /home/yacine_zahidi_orange_com/envs/general-env39/lib/python3.9/site-packages/data/models/blender/blender_90M/model.checkpoint.dict\n",
      "19:53:48 | num words = 54944\n",
      "19:53:48 | TransformerGenerator: full interactive mode on.\n",
      "19:53:49 | \u001B[33mDEPRECATED: XLM should only be used for backwards compatibility, as it involves a less-stable layernorm operation.\u001B[0m\n",
      "19:53:51 | Total parameters: 87,508,992 (87,508,992 trainable)\n",
      "19:53:51 | Loading existing model params from /home/yacine_zahidi_orange_com/envs/general-env39/lib/python3.9/site-packages/data/models/blender/blender_90M/model.checkpoint\n",
      "19:53:52 | Opt:\n",
      "19:53:52 |     activation: gelu\n",
      "19:53:52 |     adafactor_eps: '[1e-30, 0.001]'\n",
      "19:53:52 |     adam_eps: 1e-08\n",
      "19:53:52 |     add_p1_after_newln: False\n",
      "19:53:52 |     aggregate_micro: False\n",
      "19:53:52 |     allow_missing_init_opts: False\n",
      "19:53:52 |     attention_dropout: 0.0\n",
      "19:53:52 |     batchsize: 256\n",
      "19:53:52 |     beam_block_full_context: False\n",
      "19:53:52 |     beam_block_list_filename: None\n",
      "19:53:52 |     beam_block_ngram: 3\n",
      "19:53:52 |     beam_context_block_ngram: 3\n",
      "19:53:52 |     beam_delay: 30\n",
      "19:53:52 |     beam_length_penalty: 0.65\n",
      "19:53:52 |     beam_min_length: 20\n",
      "19:53:52 |     beam_size: 10\n",
      "19:53:52 |     betas: '[0.9, 0.999]'\n",
      "19:53:52 |     bpe_add_prefix_space: None\n",
      "19:53:52 |     bpe_debug: False\n",
      "19:53:52 |     bpe_dropout: None\n",
      "19:53:52 |     bpe_merge: None\n",
      "19:53:52 |     bpe_vocab: None\n",
      "19:53:52 |     checkpoint_activations: False\n",
      "19:53:52 |     compute_tokenized_bleu: False\n",
      "19:53:52 |     datapath: /home/yacine_zahidi_orange_com/envs/general-env39/lib/python3.9/site-packages/data\n",
      "19:53:52 |     datatype: train\n",
      "19:53:52 |     delimiter: '\\n'\n",
      "19:53:52 |     dict_class: parlai.core.dict:DictionaryAgent\n",
      "19:53:52 |     dict_endtoken: __end__\n",
      "19:53:52 |     dict_file: /home/yacine_zahidi_orange_com/envs/general-env39/lib/python3.9/site-packages/data/models/blender/blender_90M/model.checkpoint.dict\n",
      "19:53:52 |     dict_include_test: False\n",
      "19:53:52 |     dict_include_valid: False\n",
      "19:53:52 |     dict_initpath: None\n",
      "19:53:52 |     dict_language: english\n",
      "19:53:52 |     dict_loaded: True\n",
      "19:53:52 |     dict_lower: True\n",
      "19:53:52 |     dict_max_ngram_size: -1\n",
      "19:53:52 |     dict_maxexs: -1\n",
      "19:53:52 |     dict_maxtokens: -1\n",
      "19:53:52 |     dict_minfreq: 0\n",
      "19:53:52 |     dict_nulltoken: __null__\n",
      "19:53:52 |     dict_starttoken: __start__\n",
      "19:53:52 |     dict_textfields: text,labels\n",
      "19:53:52 |     dict_tokenizer: bpe\n",
      "19:53:52 |     dict_unktoken: __unk__\n",
      "19:53:52 |     display_add_fields: \n",
      "19:53:52 |     display_examples: False\n",
      "19:53:52 |     display_prettify: False\n",
      "19:53:52 |     download_path: None\n",
      "19:53:52 |     dropout: 0.1\n",
      "19:53:52 |     dynamic_batching: None\n",
      "19:53:52 |     embedding_projection: random\n",
      "19:53:52 |     embedding_size: 512\n",
      "19:53:52 |     embedding_type: random\n",
      "19:53:52 |     embeddings_scale: True\n",
      "19:53:52 |     eval_batchsize: None\n",
      "19:53:52 |     eval_dynamic_batching: None\n",
      "19:53:52 |     evaltask: None\n",
      "19:53:52 |     ffn_size: 2048\n",
      "19:53:52 |     final_extra_opt: \n",
      "19:53:52 |     force_fp16_tokens: True\n",
      "19:53:52 |     fp16: True\n",
      "19:53:52 |     fp16_impl: safe\n",
      "19:53:52 |     fromfile_datapath: ./convai3data\n",
      "19:53:52 |     fromfile_datatype_extension: True\n",
      "19:53:52 |     gpu: 0\n",
      "19:53:52 |     gpu_beam_blocking: False\n",
      "19:53:52 |     gradient_clip: 0.1\n",
      "19:53:52 |     hide_labels: False\n",
      "19:53:52 |     history_add_global_end_token: None\n",
      "19:53:52 |     history_reversed: False\n",
      "19:53:52 |     history_size: -1\n",
      "19:53:52 |     image_cropsize: 224\n",
      "19:53:52 |     image_mode: raw\n",
      "19:53:52 |     image_size: 256\n",
      "19:53:52 |     include_checked_sentence: True\n",
      "19:53:52 |     include_knowledge: True\n",
      "19:53:52 |     include_knowledge_separator: False\n",
      "19:53:52 |     inference: beam\n",
      "19:53:52 |     init_model: /home/yacine_zahidi_orange_com/envs/general-env39/lib/python3.9/site-packages/data/models/blender/blender_90M/model.checkpoint\n",
      "19:53:52 |     init_opt: None\n",
      "19:53:52 |     interactive_mode: True\n",
      "19:53:52 |     interactive_task: True\n",
      "19:53:52 |     invsqrt_lr_decay_gamma: -1\n",
      "19:53:52 |     is_debug: False\n",
      "19:53:52 |     label_truncate: 128\n",
      "19:53:52 |     label_type: response\n",
      "19:53:52 |     learn_positional_embeddings: True\n",
      "19:53:52 |     learningrate: 7.5e-06\n",
      "19:53:52 |     local_human_candidates_file: None\n",
      "19:53:52 |     log_every_n_secs: 2\n",
      "19:53:52 |     log_every_n_steps: 50\n",
      "19:53:52 |     log_keep_fields: all\n",
      "19:53:52 |     loglevel: info\n",
      "19:53:52 |     lr_scheduler: reduceonplateau\n",
      "19:53:52 |     lr_scheduler_decay: 0.5\n",
      "19:53:52 |     lr_scheduler_patience: 3\n",
      "19:53:52 |     max_lr_steps: -1\n",
      "19:53:52 |     max_train_steps: 50000\n",
      "19:53:52 |     max_train_time: -1\n",
      "19:53:52 |     metrics: default\n",
      "19:53:52 |     model: transformer/generator\n",
      "19:53:52 |     model_file: /home/yacine_zahidi_orange_com/envs/general-env39/lib/python3.9/site-packages/data/models/blender/blender_90M/model.checkpoint\n",
      "19:53:52 |     model_parallel: False\n",
      "19:53:52 |     momentum: 0\n",
      "19:53:52 |     multitask_weights: '[1.0, 3.0, 3.0, 3.0]'\n",
      "19:53:52 |     mutators: None\n",
      "19:53:52 |     n_decoder_layers: -1\n",
      "19:53:52 |     n_encoder_layers: -1\n",
      "19:53:52 |     n_heads: 16\n",
      "19:53:52 |     n_layers: 8\n",
      "19:53:52 |     n_positions: 512\n",
      "19:53:52 |     n_segments: 0\n",
      "19:53:52 |     nesterov: True\n",
      "19:53:52 |     no_cuda: False\n",
      "19:53:52 |     num_epochs: 500.0\n",
      "19:53:52 |     num_topics: 5\n",
      "19:53:52 |     num_workers: 0\n",
      "19:53:52 |     numthreads: 1\n",
      "19:53:52 |     nus: [0.7]\n",
      "19:53:52 |     optimizer: adamax\n",
      "19:53:52 |     outfile: \n",
      "19:53:52 |     output_scaling: 1.0\n",
      "19:53:52 |     override: \"{'model_file': '/home/yacine_zahidi_orange_com/envs/general-env39/lib/python3.9/site-packages/data/models/blender/blender_90M/model.checkpoint'}\"\n",
      "19:53:52 |     parlai_home: /private/home/edinan/ParlAI\n",
      "19:53:52 |     person_tokens: False\n",
      "19:53:52 |     rank_candidates: False\n",
      "19:53:52 |     relu_dropout: 0.0\n",
      "19:53:52 |     save_after_valid: True\n",
      "19:53:52 |     save_every_n_secs: 600.0\n",
      "19:53:52 |     save_format: conversations\n",
      "19:53:52 |     seed: None\n",
      "19:53:52 |     share_word_embeddings: True\n",
      "19:53:52 |     short_final_eval: False\n",
      "19:53:52 |     show_advanced_args: False\n",
      "19:53:52 |     single_turn: False\n",
      "19:53:52 |     skip_generation: False\n",
      "19:53:52 |     special_tok_lst: None\n",
      "19:53:52 |     split_lines: False\n",
      "19:53:52 |     starttime: Feb10_07-25\n",
      "19:53:52 |     task: fromfile:parlaiformat\n",
      "19:53:52 |     teacher_seed: None\n",
      "19:53:52 |     temperature: 1.0\n",
      "19:53:52 |     tensorboard_log: False\n",
      "19:53:52 |     tensorboard_logdir: None\n",
      "19:53:52 |     text_truncate: 512\n",
      "19:53:52 |     topk: 10\n",
      "19:53:52 |     topp: 0.9\n",
      "19:53:52 |     train_experiencer_only: False\n",
      "19:53:52 |     truncate: -1\n",
      "19:53:52 |     update_freq: 1\n",
      "19:53:52 |     use_reply: label\n",
      "19:53:52 |     validation_cutoff: 1.0\n",
      "19:53:52 |     validation_every_n_epochs: 0.25\n",
      "19:53:52 |     validation_every_n_secs: -1\n",
      "19:53:52 |     validation_every_n_steps: -1\n",
      "19:53:52 |     validation_max_exs: 20000\n",
      "19:53:52 |     validation_metric: ppl\n",
      "19:53:52 |     validation_metric_mode: min\n",
      "19:53:52 |     validation_patience: 15\n",
      "19:53:52 |     validation_share_agent: False\n",
      "19:53:52 |     variant: xlm\n",
      "19:53:52 |     verbose: False\n",
      "19:53:52 |     wandb_entity: None\n",
      "19:53:52 |     wandb_log: True\n",
      "19:53:52 |     wandb_log_model: False\n",
      "19:53:52 |     wandb_name: None\n",
      "19:53:52 |     wandb_project: None\n",
      "19:53:52 |     warmup_rate: 0.0001\n",
      "19:53:52 |     warmup_updates: -1\n",
      "19:53:52 |     weight_decay: None\n",
      "19:53:52 |     world_logs: \n",
      "\u001B[1;31mEnter [DONE] if you want to end the episode, [EXIT] to quit.\u001B[0;0m\n",
      "19:53:52 | creating task(s): interactive\n",
      "\u001B[0mEnter Your Message:\u001B[0;0m ^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/yacine_zahidi_orange_com/envs/general-env39/bin/parlai\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/home/yacine_zahidi_orange_com/envs/general-env39/lib/python3.9/site-packages/parlai/__main__.py\", line 14, in main\n",
      "    superscript_main()\n",
      "  File \"/home/yacine_zahidi_orange_com/envs/general-env39/lib/python3.9/site-packages/parlai/core/script.py\", line 325, in superscript_main\n",
      "    return SCRIPT_REGISTRY[cmd].klass._run_from_parser_and_opt(opt, parser)\n",
      "  File \"/home/yacine_zahidi_orange_com/envs/general-env39/lib/python3.9/site-packages/parlai/core/script.py\", line 108, in _run_from_parser_and_opt\n",
      "    return script.run()\n",
      "  File \"/home/yacine_zahidi_orange_com/envs/general-env39/lib/python3.9/site-packages/parlai/scripts/interactive.py\", line 118, in run\n",
      "    return interactive(self.opt)\n",
      "  File \"/home/yacine_zahidi_orange_com/envs/general-env39/lib/python3.9/site-packages/parlai/scripts/interactive.py\", line 93, in interactive\n",
      "    world.parley()\n",
      "  File \"/home/yacine_zahidi_orange_com/envs/general-env39/lib/python3.9/site-packages/parlai/tasks/interactive/worlds.py\", line 75, in parley\n",
      "    act = deepcopy(agents[0].act())\n",
      "  File \"/home/yacine_zahidi_orange_com/envs/general-env39/lib/python3.9/site-packages/parlai/agents/local_human/local_human.py\", line 75, in act\n",
      "    reply_text = input(colorize(\"Enter Your Message:\", 'text') + ' ')\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "File \u001B[0;32m~/envs/general-env39/lib/python3.9/site-packages/IPython/utils/_process_posix.py:153\u001B[0m, in \u001B[0;36mProcessHandler.system\u001B[0;34m(self, cmd)\u001B[0m\n\u001B[1;32m    150\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m    151\u001B[0m     \u001B[38;5;66;03m# res is the index of the pattern that caused the match, so we\u001B[39;00m\n\u001B[1;32m    152\u001B[0m     \u001B[38;5;66;03m# know whether we've finished (if we matched EOF) or not\u001B[39;00m\n\u001B[0;32m--> 153\u001B[0m     res_idx \u001B[38;5;241m=\u001B[39m \u001B[43mchild\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexpect_list\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpatterns\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_timeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    154\u001B[0m     \u001B[38;5;28mprint\u001B[39m(child\u001B[38;5;241m.\u001B[39mbefore[out_size:]\u001B[38;5;241m.\u001B[39mdecode(enc, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mreplace\u001B[39m\u001B[38;5;124m'\u001B[39m), end\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[0;32m~/envs/general-env39/lib/python3.9/site-packages/pexpect/spawnbase.py:372\u001B[0m, in \u001B[0;36mSpawnBase.expect_list\u001B[0;34m(self, pattern_list, timeout, searchwindowsize, async_, **kw)\u001B[0m\n\u001B[1;32m    371\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 372\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mexp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexpect_loop\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/envs/general-env39/lib/python3.9/site-packages/pexpect/expect.py:169\u001B[0m, in \u001B[0;36mExpecter.expect_loop\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    168\u001B[0m \u001B[38;5;66;03m# Still have time left, so read more data\u001B[39;00m\n\u001B[0;32m--> 169\u001B[0m incoming \u001B[38;5;241m=\u001B[39m \u001B[43mspawn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_nonblocking\u001B[49m\u001B[43m(\u001B[49m\u001B[43mspawn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmaxread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    170\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mspawn\u001B[38;5;241m.\u001B[39mdelayafterread \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m~/envs/general-env39/lib/python3.9/site-packages/pexpect/pty_spawn.py:500\u001B[0m, in \u001B[0;36mspawn.read_nonblocking\u001B[0;34m(self, size, timeout)\u001B[0m\n\u001B[1;32m    497\u001B[0m \u001B[38;5;66;03m# Because of the select(0) check above, we know that no data\u001B[39;00m\n\u001B[1;32m    498\u001B[0m \u001B[38;5;66;03m# is available right now. But if a non-zero timeout is given\u001B[39;00m\n\u001B[1;32m    499\u001B[0m \u001B[38;5;66;03m# (possibly timeout=None), we call select() with a timeout.\u001B[39;00m\n\u001B[0;32m--> 500\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (timeout \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m \u001B[43mselect\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[1;32m    501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m(spawn, \u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39mread_nonblocking(size)\n",
      "File \u001B[0;32m~/envs/general-env39/lib/python3.9/site-packages/pexpect/pty_spawn.py:450\u001B[0m, in \u001B[0;36mspawn.read_nonblocking.<locals>.select\u001B[0;34m(timeout)\u001B[0m\n\u001B[1;32m    449\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mselect\u001B[39m(timeout):\n\u001B[0;32m--> 450\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mselect_ignore_interrupts\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mchild_fd\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[0;32m~/envs/general-env39/lib/python3.9/site-packages/pexpect/utils.py:143\u001B[0m, in \u001B[0;36mselect_ignore_interrupts\u001B[0;34m(iwtd, owtd, ewtd, timeout)\u001B[0m\n\u001B[1;32m    142\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 143\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mselect\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mselect\u001B[49m\u001B[43m(\u001B[49m\u001B[43miwtd\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mowtd\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mewtd\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    144\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mInterruptedError\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[65], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mget_ipython\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msystem\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mparlai interactive --mf /home/yacine_zahidi_orange_com/envs/general-env39/lib/python3.9/site-packages/data/models/blender/blender_90M/model.checkpoint\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/envs/general-env39/lib/python3.9/site-packages/ipykernel/zmqshell.py:649\u001B[0m, in \u001B[0;36mZMQInteractiveShell.system_piped\u001B[0;34m(self, cmd)\u001B[0m\n\u001B[1;32m    647\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39muser_ns[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_exit_code\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m system(cmd)\n\u001B[1;32m    648\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 649\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39muser_ns[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_exit_code\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[43msystem\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvar_expand\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcmd\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdepth\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/envs/general-env39/lib/python3.9/site-packages/IPython/utils/_process_posix.py:177\u001B[0m, in \u001B[0;36mProcessHandler.system\u001B[0;34m(self, cmd)\u001B[0m\n\u001B[1;32m    174\u001B[0m         \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[1;32m    175\u001B[0m     \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    176\u001B[0m         \u001B[38;5;66;03m# Ensure the subprocess really is terminated\u001B[39;00m\n\u001B[0;32m--> 177\u001B[0m         \u001B[43mchild\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mterminate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mforce\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m    178\u001B[0m \u001B[38;5;66;03m# add isalive check, to ensure exitstatus is set:\u001B[39;00m\n\u001B[1;32m    179\u001B[0m child\u001B[38;5;241m.\u001B[39misalive()\n",
      "File \u001B[0;32m~/envs/general-env39/lib/python3.9/site-packages/pexpect/pty_spawn.py:642\u001B[0m, in \u001B[0;36mspawn.terminate\u001B[0;34m(self, force)\u001B[0m\n\u001B[1;32m    640\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    641\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mkill(signal\u001B[38;5;241m.\u001B[39mSIGHUP)\n\u001B[0;32m--> 642\u001B[0m     \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdelayafterterminate\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    643\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39misalive():\n\u001B[1;32m    644\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "!parlai interactive --mf /home/yacine_zahidi_orange_com/envs/general-env39/lib/python3.9/site-packages/data/models/blender/blender_90M/model.checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac17faa-f7e3-45d7-9f54-f82e3a1adb59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
